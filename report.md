# REPORT - LAB 9: ULTIMATE PRACTICE
## MÃ”N: NHáº¬P MÃ”N Ká»¸ THUáº¬T Dá»® LIá»†U - Lá»šP: DHKHDL19A
## Danh sÃ¡ch thÃ nh viÃªn:
>> 1. BÃ¹i Quang ThÃ nh
>> 2. Nguyá»…n Thá»‹ PhÆ°Æ¡ng Tháº£o
>> 3. TrÆ°Æ¡ng Äáº·ng HoÃ ng Tuyáº¿n

# BÃ€I LÃ€M
> 1. ÄÄƒng nháº­p vÃ o tÃ i khoáº£ng Github

> 2. Truy cáº­p vÃ o link:
> 
> 3. Chá»n fork
![image](https://github.com/user-attachments/assets/78bc5f7e-3354-46d3-93ae-37df89da9613)

> 4. Click Create fork
![image](https://github.com/user-attachments/assets/bf0a8369-8568-401f-a337-7457d2c25a3b)

## EXERCISE 1

> 1. Thá»±c thi lá»‡nh sau trong CMD: git clone Ä‘á»ƒ clone GitHub repo vá» mÃ¡y cá»§a mÃ¬nh
![image](https://github.com/user-attachments/assets/03a1821e-dd25-4748-931d-afee36e47d7e).

> 2. Sau Ä‘Ã³ tiáº¿n hÃ nh cháº¡y lá»‡nh `cd data-engineering-practice/Exercises/Exercise-1` Ä‘á»ƒ thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c Exercise-1

> 3. Tiáº¿p tá»¥c thá»±c hiá»‡n lá»‡nh: `docker build --tag=exercise-1 .` Ä‘á»ƒ build Docker image QuÃ¡ trÃ¬nh sáº½ máº¥t vÃ i phÃºt
![70fb32a899772b297266](https://github.com/user-attachments/assets/250e5f8f-4bf3-4263-b32d-9832969553f4)
![3c90cf92794dcb13925c](https://github.com/user-attachments/assets/9e3bd508-8290-41bf-8e1a-6223464211c3)
![7a5be3c75018e246bb09](https://github.com/user-attachments/assets/ee05f4d0-72e5-4105-8326-aef28a6f8d41)


> 4. Sá»­ dá»¥ng Visual Ä‘á»ƒ cháº¡y main.py
![c7929cded400665e3f11](https://github.com/user-attachments/assets/e9934529-5d0d-4e97-985f-69e06a9041eb)


> ##### Code sá»­ dá»¥ng cho main.py
```
# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
import os               # LÃ m viá»‡c vá»›i há»‡ thá»‘ng file (táº¡o thÆ° má»¥c, Ä‘Æ°á»ng dáº«n, xÃ³a file)
import requests         # Gá»­i HTTP request Ä‘á»ƒ táº£i file tá»« Internet
import zipfile          # Giáº£i nÃ©n cÃ¡c file .zip

# Danh sÃ¡ch cÃ¡c URL chá»©a dá»¯ liá»‡u cáº§n táº£i xuá»‘ng
download_uris = [
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2018_Q4.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q1.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q2.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q3.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q4.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2020_Q1.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2220_Q1.zip",  # URL sai Ä‘á»ƒ kiá»ƒm tra báº¯t lá»—i
]

# ThÆ° má»¥c lÆ°u file sau khi táº£i vÃ  giáº£i nÃ©n
DOWNLOAD_DIR = "downloads"

# HÃ m xá»­ lÃ½ táº£i xuá»‘ng vÃ  giáº£i nÃ©n má»™t file
def download_and_extract(url):
    # Láº¥y tÃªn file tá»« URL (vd: Divvy_Trips_2019_Q1.zip)
    filename = url.split("/")[-1]
    zip_path = os.path.join(DOWNLOAD_DIR, filename)  # ÄÆ°á»ng dáº«n lÆ°u file .zip

    try:
        print(f"Downloading: {filename}")

        # Gá»­i GET request Ä‘áº¿n URL
        response = requests.get(url)
        response.raise_for_status()  # Náº¿u lá»—i HTTP (vd: 404, 403) sáº½ raise exception

        # Ghi ná»™i dung táº£i Ä‘Æ°á»£c vÃ o file .zip
        with open(zip_path, "wb") as f:
            f.write(response.content)

        # Má»Ÿ file .zip vÃ  giáº£i nÃ©n táº¥t cáº£ ná»™i dung vÃ o thÆ° má»¥c DOWNLOAD_DIR
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(DOWNLOAD_DIR)

        # XÃ³a file .zip sau khi giáº£i nÃ©n thÃ nh cÃ´ng
        os.remove(zip_path)

        print(f"âœ“ Done: {filename}")

    # Báº¯t lá»—i HTTP (URL lá»—i, khÃ´ng tá»“n táº¡i...)
    except requests.exceptions.HTTPError as http_err:
        print(f"âŒ HTTP error for {filename}: {http_err}")

    # Báº¯t lá»—i náº¿u file táº£i vá» khÃ´ng pháº£i file zip há»£p lá»‡
    except zipfile.BadZipFile:
        print(f"âŒ Not a valid zip file: {filename}")

    # Báº¯t cÃ¡c lá»—i khÃ¡c
    except Exception as e:
        print(f"âŒ Failed {filename}: {e}")

# HÃ m main Ä‘iá»u phá»‘i quÃ¡ trÃ¬nh
def main():
    # Táº¡o thÆ° má»¥c "downloads" náº¿u chÆ°a tá»“n táº¡i
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)

    # Láº·p qua tá»«ng URL trong danh sÃ¡ch vÃ  xá»­ lÃ½
    for url in download_uris:
        download_and_extract(url)

# Khi cháº¡y script trá»±c tiáº¿p, gá»i hÃ m main
if __name__ == "__main__":
    main()

```
> Äoáº¡n code trÃªn thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥: 
- Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i

- Táº£i tá»«ng file tá»« danh sÃ¡ch download\_uris

- Giá»¯ tÃªn gá»‘c cá»§a file tá»« URL

- Giáº£i nÃ©n .zip thÃ nh .csv

- XÃ³a file .zip sau khi giáº£i nÃ©n

- Bá» qua URL khÃ´ng há»£p lá»‡ (vÃ­ dá»¥: cÃ¡i Divvy\_Trips\_2220\_Q1.zip khÃ´ng tá»“n táº¡i)

> 5. Sau khi save `main.py`, cháº¡y lá»‡nh `docker-compose up run` (máº¥t khoáº£ng 5 phÃºt)
![bada83a1af7f1d21446e](https://github.com/user-attachments/assets/0c8b5d85-dd88-486c-b4bf-f1f9ccfa7eab)


## EXERCISE 2

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-2`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-2 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![1504b98db053020d5b42](https://github.com/user-attachments/assets/734aab65-dc74-4c71-ab0f-d5de198ec074)

> 3. Sau khi build xong, truy cáº­p file main.py báº±ng VS code


##### Ná»™i dung file main.py

```import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

# URL cá»§a trang web chá»©a cÃ¡c tá»‡p cáº§n táº£i
BASE_URL = "https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/"

# Dáº¥u thá»i gian cáº§n tÃ¬m kiáº¿m trÃªn trang web
TARGET_TIMESTAMP = "2024-01-19 10:27"

def find_target_file():
    """
    HÃ m nÃ y sáº½ duyá»‡t qua trang web, tÃ¬m kiáº¿m tá»‡p vá»›i dáº¥u thá»i gian
    TARGET_TIMESTAMP vÃ  tráº£ vá» tÃªn tá»‡p tÆ°Æ¡ng á»©ng.
    """
    response = requests.get(BASE_URL)  # Gá»­i yÃªu cáº§u GET tá»›i trang web
    response.raise_for_status()  # Kiá»ƒm tra náº¿u yÃªu cáº§u thÃ nh cÃ´ng

    soup = BeautifulSoup(response.text, 'lxml')  # PhÃ¢n tÃ­ch trang HTML

    # TÃ¬m táº¥t cáº£ cÃ¡c dÃ²ng trong báº£ng
    rows = soup.find_all("tr")

    for row in rows:
        cols = row.find_all("td")  # TÃ¬m cÃ¡c Ã´ trong dÃ²ng
        if len(cols) >= 2:
            timestamp = cols[1].text.strip()  # Láº¥y dáº¥u thá»i gian
            if timestamp == TARGET_TIMESTAMP:
                filename = cols[0].text.strip()  # Láº¥y tÃªn tá»‡p
                return filename  # Tráº£ vá» tÃªn tá»‡p náº¿u tÃ¬m tháº¥y

    # Náº¿u khÃ´ng tÃ¬m tháº¥y tá»‡p vá»›i dáº¥u thá»i gian yÃªu cáº§u
    raise Exception(f"File with timestamp {TARGET_TIMESTAMP} not found.")

def download_file(filename):
    """
    HÃ m nÃ y sáº½ táº£i tá»‡p tá»« URL vÃ  lÆ°u tá»‡p vÃ o thÆ° má»¥c 'downloads'.
    """
    download_url = BASE_URL + filename  # XÃ¢y dá»±ng URL Ä‘áº§y Ä‘á»§ Ä‘á»ƒ táº£i tá»‡p
    local_path = os.path.join("downloads", filename)  # ÄÆ°á»ng dáº«n lÆ°u tá»‡p

    # Táº¡o thÆ° má»¥c 'downloads' náº¿u chÆ°a tá»“n táº¡i
    os.makedirs("downloads", exist_ok=True)

    # Gá»­i yÃªu cáº§u GET Ä‘á»ƒ táº£i tá»‡p
    response = requests.get(download_url)
    response.raise_for_status()  # Kiá»ƒm tra náº¿u yÃªu cáº§u thÃ nh cÃ´ng

    # LÆ°u tá»‡p vÃ o há»‡ thá»‘ng
    with open(local_path, 'wb') as f:
        f.write(response.content)
    print(f"Downloaded file to {local_path}")  # ThÃ´ng bÃ¡o tá»‡p Ä‘Ã£ Ä‘Æ°á»£c táº£i
    return local_path  # Tráº£ vá» Ä‘Æ°á»ng dáº«n cá»§a tá»‡p táº£i vá»

def analyze_file(filepath):
    """
    HÃ m nÃ y sáº½ má»Ÿ tá»‡p CSV, tÃ¬m báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t vÃ  in ra.
    """
    df = pd.read_csv(filepath)  # Äá»c tá»‡p CSV vÃ o DataFrame cá»§a Pandas

    # Kiá»ƒm tra xem cá»™t 'HourlyDryBulbTemperature' cÃ³ tá»“n táº¡i khÃ´ng
    if 'HourlyDryBulbTemperature' not in df.columns:
        raise Exception("'HourlyDryBulbTemperature' column not found in the file.")  # Náº¿u khÃ´ng cÃ³, nÃ©m lá»—i

    # Chuyá»ƒn Ä‘á»•i cá»™t 'HourlyDryBulbTemperature' thÃ nh kiá»ƒu sá»‘ (náº¿u cáº§n)
    df['HourlyDryBulbTemperature'] = pd.to_numeric(df['HourlyDryBulbTemperature'], errors='coerce')

    # TÃ¬m giÃ¡ trá»‹ nhiá»‡t Ä‘á»™ cao nháº¥t
    max_temp = df['HourlyDryBulbTemperature'].max()
    # Lá»c ra cÃ¡c báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t
    hottest_records = df[df['HourlyDryBulbTemperature'] == max_temp]

    print("\nğŸŒ¡ Records with the highest HourlyDryBulbTemperature:")
    print(hottest_records)  # In ra cÃ¡c báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t

def main():
    """
    HÃ m chÃ­nh sáº½ gá»i cÃ¡c hÃ m trÃªn Ä‘á»ƒ tÃ¬m kiáº¿m tá»‡p, táº£i tá»‡p vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u.
    """
    try:
        print("Looking for file...")  # ThÃ´ng bÃ¡o Ä‘ang tÃ¬m kiáº¿m tá»‡p
        filename = find_target_file()  # TÃ¬m tá»‡p vá»›i dáº¥u thá»i gian cáº§n tÃ¬m

        print(f"Found file: {filename}")  # ThÃ´ng bÃ¡o tÃ¬m tháº¥y tá»‡p
        filepath = download_file(filename)  # Táº£i tá»‡p vá»

        print("Analyzing file...")  # ThÃ´ng bÃ¡o Ä‘ang phÃ¢n tÃ­ch tá»‡p
        analyze_file(filepath)  # PhÃ¢n tÃ­ch tá»‡p Ä‘á»ƒ tÃ¬m báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t

    except Exception as e:
        print(f"Error: {e}")  # In ra lá»—i náº¿u cÃ³

# Cháº¡y hÃ m main náº¿u tá»‡p nÃ y Ä‘Æ°á»£c thá»±c thi trá»±c tiáº¿p
if __name__ == "__main__":
    main()

```

> 4. Sau khi save file main.py, cháº¡y dÃ²ng lá»‡nh `docker-compose up run`

> 5. Káº¿t quáº£ thu Ä‘Æ°á»£c
> ![8800406e25b797e9cea6](https://github.com/user-attachments/assets/3b78c261-28a4-4f6a-986c-dab636f84045)

## EXERCISE 3

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-3`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-3 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/b4dc7f5e-843b-4e94-810b-596e8595e37e)

> 3. Sau khi build xong, truy cáº­p file `main.py` báº±ng VS code

##### Code sá»­ dá»¥ng cho main.py:
```
import io
import gzip
import requests
from dotenv import load_dotenv

load_dotenv()
def download_file_from_url(url):
    response = requests.get(url)
    if response.status_code == 200:
        return response.content
    else:
        print(f"Error downloading file: {response.status_code}")
        return None
def main():
    url = 'https://data.commoncrawl.org/crawl-data/CC-MAIN-2022-05/wet.paths.gz'
    gz_content = download_file_from_url(url)
    
    if gz_content:
        with gzip.GzipFile(fileobj=io.BytesIO(gz_content)) as f:
            first_line = f.readline().decode('utf-8').strip() 
            print(f"First line from wet.paths.gz: {first_line}")
            uri = first_line
            print(f"Extracted URI: {uri}")
            print("\nPrinting the first 50 lines from wet.paths.gz:")
            for i, line in enumerate(f):
                if i >= 50:  
                    break
                print(line.decode('utf-8').strip()) 
if __name__ == "__main__":
    main()
```
> 4. Sau khi lÆ°u file `main.py`, thá»±c hiá»‡n lá»‡nh `docker-compose up run`
> 5. Káº¿t quáº£ sau khi thá»±c hiá»‡n
![Screenshot 2025-04-24 133824](https://github.com/user-attachments/assets/9b19ff56-eee5-41e7-a62b-5050c8958066)


## EXERCISE-4

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-4`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-4 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/0429e78f-9d6b-4c9c-8d67-c06d6831a270)

> 3. Ná»™i dung file `main.py`
```
import os
import json
import csv
import glob

def flatten\_json(nested\_json, parent\_key='', sep='\_'):

Â  Â  """Giáº£i nÃ©n JSON lá»“ng nhau thÃ nh cáº¥u trÃºc pháº³ng (flat structure)"""

Â  Â  items = []

Â  Â  if isinstance(nested\_json, dict): Â # Kiá»ƒm tra náº¿u lÃ  dictionary

Â  Â  Â  Â  for k, v in nested\_json.items():

Â  Â  Â  Â  Â  Â  new\_key = f"{parent\_key}{sep}{k}" if parent\_key else k

Â  Â  Â  Â  Â  Â  if isinstance(v, dict): Â # Náº¿u giÃ¡ trá»‹ lÃ  dict, tiáº¿p tá»¥c giáº£i nÃ©n

Â  Â  Â  Â  Â  Â  Â  Â  items.extend(flatten\_json(v, new\_key, sep=sep).items())

Â  Â  Â  Â  Â  Â  elif isinstance(v, list): Â # Náº¿u giÃ¡ trá»‹ lÃ  list, giáº£i nÃ©n tá»«ng pháº§n tá»­

Â  Â  Â  Â  Â  Â  Â  Â  for i, sub\_item in enumerate(v):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  items.extend(flatten\_json(sub\_item, f"{new\_key}{sep}{i}", sep=sep).items())

Â  Â  Â  Â  Â  Â  else: Â # Náº¿u giÃ¡ trá»‹ khÃ´ng pháº£i dict hoáº·c list (vÃ­ dá»¥ nhÆ° sá»‘, chuá»—i, boolean)

Â  Â  Â  Â  Â  Â  Â  Â  items.append((new\_key, v))

Â  Â  elif isinstance(nested\_json, list): Â # Kiá»ƒm tra náº¿u lÃ  list

Â  Â  Â  Â  for i, sub\_item in enumerate(nested\_json):

Â  Â  Â  Â  Â  Â  items.extend(flatten\_json(sub\_item, f"{parent\_key}{sep}{i}", sep=sep).items())

Â  Â  else:

Â  Â  Â  Â  # Náº¿u giÃ¡ trá»‹ lÃ  kiá»ƒu khÃ¡c (vÃ­ dá»¥ float, int, string), tráº£ vá» giÃ¡ trá»‹ trá»±c tiáº¿p

Â  Â  Â  Â  items.append((parent\_key, nested\_json))

Â  Â  return dict(items)

def convert\_json\_to\_csv(json\_file, csv\_file):

Â  Â  """Chuyá»ƒn Ä‘á»•i tá»‡p JSON thÃ nh tá»‡p CSV"""

Â  Â  with open(json\_file, 'r') as f:

Â  Â  Â  Â  data = json.load(f)

Â  Â  # Giáº£i nÃ©n JSON lá»“ng nhau

Â  Â  flat\_data = flatten\_json(data)

Â  Â  # LÆ°u dá»¯ liá»‡u vÃ o CSV

Â  Â  with open(csv\_file, 'w', newline='', encoding='utf-8') as f:

Â  Â  Â  Â  writer = csv.DictWriter(f, fieldnames=flat\_data.keys())

Â  Â  Â  Â  writer.writeheader()

Â  Â  Â  Â  writer.writerow(flat\_data)

def process\_json\_files\_in\_directory(data\_directory):

Â  Â  """Duyá»‡t qua thÆ° má»¥c vÃ  chuyá»ƒn Ä‘á»•i táº¥t cáº£ tá»‡p JSON thÃ nh CSV"""

Â  Â  # TÃ¬m táº¥t cáº£ tá»‡p .json trong thÆ° má»¥c vÃ  cÃ¡c thÆ° má»¥c con

Â  Â  json\_files = glob.glob(os.path.join(data\_directory, '**', '*.json'), recursive=True)

Â  Â  for json\_file in json\_files:

Â  Â  Â  Â  csv\_file = json\_file.replace('.json', '.csv')

Â  Â  Â  Â  convert\_json\_to\_csv(json\_file, csv\_file)

Â  Â  Â  Â  print(f"ÄÃ£ chuyá»ƒn Ä‘á»•i {json\_file} thÃ nh {csv\_file}")

def main():

Â  Â  # ThÆ° má»¥c chá»©a dá»¯ liá»‡u

Â  Â  data\_directory = './data' Â # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n náº¿u cáº§n

Â  Â  process\_json\_files\_in\_directory(data\_directory)

if \_\_name\_\_ == "\_\_main\_\_":

Â  Â  main()
```

> 4. Sau khi save file ` main.py`, thá»±c thi lá»‡nh `docker-compose up run`
> 5. Káº¿t quáº£ sau khi thá»±c hiá»‡n:

![image](https://github.com/user-attachments/assets/52637e8a-7e04-48de-9cfc-7dc66e3c5ea5)

![image](https://github.com/user-attachments/assets/ca55d07c-a19c-4235-aa86-2c2815547f2b)

![image](https://github.com/user-attachments/assets/00fd665a-2b77-4ac1-9dc3-c069996521ad)

## EXERCISE-5

> 1.Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-5`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-5 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/3eb12b93-1146-4adf-bba8-5ad4cc3750fd)

#### Ná»™i dung file main.py:
```
import psycopg2
import csv

# Káº¿t ná»‘i Ä‘áº¿n PostgreSQL
conn = psycopg2.connect(

Â  Â  dbname="postgres", Â # TÃªn cÆ¡ sá»Ÿ dá»¯ liá»‡u

Â  Â  user="postgres", Â  Â # TÃªn ngÆ°á»i dÃ¹ng PostgreSQL

Â  Â  password="postgres",# Máº­t kháº©u PostgreSQL

Â  Â  host="postgres", Â  Â # MÃ¡y chá»§ (PostgreSQL cháº¡y trÃªn localhost)

Â  Â  port="5432" Â  Â  Â  Â  # Cá»•ng PostgreSQL (máº·c Ä‘á»‹nh)

)

# Táº¡o má»™t con trá» Ä‘á»ƒ thá»±c thi cÃ¡c cÃ¢u lá»‡nh SQL

with conn.cursor() as cur:

Â  Â  # 1. XÃ³a táº¥t cáº£ cÃ¡c rÃ ng buá»™c khÃ³a ngoáº¡i náº¿u cÃ³

Â  Â  remove\_constraints = """

Â  Â  ALTER TABLE IF EXISTS orders DROP CONSTRAINT IF EXISTS orders\_product\_id\_fkey;

Â  Â  """

Â  Â  cur.execute(remove\_constraints)

Â  Â  conn.commit()

Â  Â  # 2. XÃ³a cÃ¡c báº£ng náº¿u Ä‘Ã£ tá»“n táº¡i

Â  Â  drop\_tables = """

Â  Â  DROP TABLE IF EXISTS transactions, accounts, products CASCADE;

Â  Â  """

Â  Â  cur.execute(drop\_tables)

Â  Â  conn.commit()

Â  Â  # 3. Táº¡o láº¡i cÃ¡c báº£ng

Â  Â  create\_products\_table = """

Â  Â  CREATE TABLE IF NOT EXISTS products (

Â  Â  Â  Â  product\_id INT PRIMARY KEY,

Â  Â  Â  Â  product\_code VARCHAR(10),

Â  Â  Â  Â  product\_description VARCHAR(255)

Â  Â  );

Â  Â  """

Â  Â  

Â  Â  # Táº¡o báº£ng accounts

Â  Â  create\_accounts\_table = """

Â  Â  CREATE TABLE IF NOT EXISTS accounts (

Â  Â  Â  Â  customer\_id INT PRIMARY KEY,

Â  Â  Â  Â  first\_name VARCHAR(100),

Â  Â  Â  Â  last\_name VARCHAR(100),

Â  Â  Â  Â  address\_1 VARCHAR(255),

Â  Â  Â  Â  address\_2 VARCHAR(255),

Â  Â  Â  Â  city VARCHAR(100),

Â  Â  Â  Â  state VARCHAR(50),

Â  Â  Â  Â  zip\_code VARCHAR(20),

Â  Â  Â  Â  join\_date DATE

Â  Â  );

Â  Â  """

Â  Â  

Â  Â  # Táº¡o báº£ng transactions (sau khi báº£ng products Ä‘Ã£ Ä‘Æ°á»£c táº¡o)

Â  Â  create\_transactions\_table = """

Â  Â  CREATE TABLE IF NOT EXISTS transactions (

Â  Â  Â  Â  transaction\_id VARCHAR(50) PRIMARY KEY,

Â  Â  Â  Â  transaction\_date DATE,

Â  Â  Â  Â  product\_id INT,

Â  Â  Â  Â  product\_code VARCHAR(10),

Â  Â  Â  Â  product\_description VARCHAR(255),

Â  Â  Â  Â  quantity INT,

Â  Â  Â  Â  account\_id INT

Â  Â  );

Â  Â  """

Â  Â  

Â  Â  # 4. Cháº¡y cÃ¡c cÃ¢u lá»‡nh táº¡o báº£ng

Â  Â  print("Creating products table...")

Â  Â  cur.execute(create\_products\_table) Â # Äáº£m báº£o táº¡o báº£ng products trÆ°á»›c

Â  Â  print("Creating accounts table...")

Â  Â  cur.execute(create\_accounts\_table)

Â  Â  print("Creating transactions table...")

Â  Â  cur.execute(create\_transactions\_table)

Â  Â  # Commit changes

Â  Â  conn.commit()

Â  Â  # 5. ThÃªm khÃ³a ngoáº¡i sau khi cÃ¡c báº£ng Ä‘Ã£ Ä‘Æ°á»£c táº¡o

Â  Â  add\_foreign\_keys = """

Â  Â  ALTER TABLE transactions

Â  Â  ADD CONSTRAINT fk\_product\_id FOREIGN KEY (product\_id) REFERENCES products(product\_id) ON DELETE CASCADE,

Â  Â  ADD CONSTRAINT fk\_account\_id FOREIGN KEY (account\_id) REFERENCES accounts(customer\_id) ON DELETE CASCADE;

Â  Â  """

Â  Â  print("Adding foreign key constraints...")

Â  Â  cur.execute(add\_foreign\_keys)

Â  Â  

Â  Â  # Commit changes

Â  Â  conn.commit()

Â  Â  # 6. ChÃ¨n dá»¯ liá»‡u tá»« CSV vÃ o cÃ¡c báº£ng

Â  Â  def load\_data\_from\_csv(csv\_file, table\_name, columns):

Â  Â  Â  Â  with open(csv\_file, 'r') as file:

Â  Â  Â  Â  Â  Â  reader = csv.reader(file)

Â  Â  Â  Â  Â  Â  next(reader) Â # Bá» qua dÃ²ng tiÃªu Ä‘á» (header row)

Â  Â  Â  Â  Â  Â  

Â  Â  Â  Â  Â  Â  for row in reader:

Â  Â  Â  Â  Â  Â  Â  Â  # Táº¡o cÃ¢u truy váº¥n Ä‘á»ƒ chÃ¨n dá»¯ liá»‡u

Â  Â  Â  Â  Â  Â  Â  Â  query = f"INSERT INTO {table\_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})"

Â  Â  Â  Â  Â  Â  Â  Â  cur.execute(query, row)

Â  Â  Â  Â  

Â  Â  Â  Â  conn.commit()

Â  Â  # 7. ChÃ¨n dá»¯ liá»‡u cho tá»«ng báº£ng

Â  Â  load\_data\_from\_csv("data/accounts.csv", "accounts", ["customer\_id", "first\_name", "last\_name", "address\_1", "address\_2", "city", "state", "zip\_code", "join\_date"])

Â  Â  load\_data\_from\_csv("data/products.csv", "products", ["product\_id", "product\_code", "product\_description"])

Â  Â  load\_data\_from\_csv("data/transactions.csv", "transactions", ["transaction\_id", "transaction\_date", "product\_id", "product\_code", "product\_description", "quantity", "account\_id"])

# 8. ÄÃ³ng káº¿t ná»‘i

conn.close()

print("Data has been loaded successfully.")
```

> 3. Sau khi lÆ°u láº¡i, thá»±c thi lá»‡nh `docker-compose up run`
> 4. Káº¿t quáº£ sau khi thá»±c hiá»‡n:
![image](https://github.com/user-attachments/assets/e4013e15-1978-4dff-926d-69ac7c8b3a3e)
> Truy váº¥n cÃ¡c báº£ng vá»«a táº¡o trong DBeaver
![image](https://github.com/user-attachments/assets/5ead3335-5ae2-4cee-b049-52af90313eae)

## PIPELINE Tá»° Äá»˜NG THá»°C HIá»†N BÃ€I Táº¬P 1- 5
#### Code cho pipeline.py:
```
import os
import subprocess

# List cÃ¡c Exercise báº¡n muá»‘n cháº¡y
exercises = ['Exercise-1', 'Exercise-2', 'Exercise-3', 'Exercise-4', 'Exercise-5']

# HÃ m kiá»ƒm tra xem image Ä‘Ã£ cÃ³ chÆ°a
def check_image_exists(image_name):
    result = subprocess.run(['docker', 'images', '-q', image_name], stdout=subprocess.PIPE)
    return result.stdout.decode().strip() != ''

# HÃ m build image náº¿u chÆ°a cÃ³
def build_image(exercise_name):
    print(f"Image {exercise_name} chÆ°a cÃ³, báº¯t Ä‘áº§u build...")
    result = subprocess.run(['docker', 'build', '-t', exercise_name, f'D:/NMKTDL/data-engineering-practice-main/Exercises/{exercise_name}'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print(f"Build image {exercise_name} tháº¥t báº¡i. Dá»«ng pipeline.")
        print(result.stderr.decode())
        exit(1)
    print(f"Build image {exercise_name} thÃ nh cÃ´ng.")

# HÃ m cháº¡y docker-compose
def run_docker_compose(exercise_name):
    print(f"Äang cháº¡y {exercise_name} báº±ng image {exercise_name}...")
    compose_file = f'D:/NMKTDL/data-engineering-practice-main/Exercises/{exercise_name}/docker-compose.yml'
    result = subprocess.run(['docker-compose', '-f', compose_file, 'up'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print(f"Lá»—i khi cháº¡y {exercise_name}. Dá»«ng pipeline.")
        print(result.stderr.decode())
        exit(1)
    
    # Kiá»ƒm tra logs cá»§a cÃ¡c container
    print("Kiá»ƒm tra logs cá»§a cÃ¡c container...")
    logs_result = subprocess.run(['docker-compose', '-f', compose_file, 'logs'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    print(logs_result.stdout.decode())  # In logs Ä‘á»ƒ xem chi tiáº¿t

    print(f"{exercise_name} Ä‘Ã£ hoÃ n táº¥t!")

# Pipeline
def run_pipeline():
    for exercise in exercises:
        # Kiá»ƒm tra image Ä‘Ã£ tá»“n táº¡i chÆ°a
        if not check_image_exists(exercise.lower()):
            build_image(exercise)
        else:
            print(f"Image {exercise} Ä‘Ã£ cÃ³ sáºµn.")
        
        # Cháº¡y docker-compose cho bÃ i
        run_docker_compose(exercise)

    print("\nPipeline hoÃ n táº¥t!")

if __name__ == "__main__":
    run_pipeline()
```
> #### Káº¿t quáº£ thá»±c hiá»‡n:
> ##### Exercise-1
> ![image](https://github.com/user-attachments/assets/63d6cecb-88f2-48c4-816d-1dfc4b767f61)
> ##### Exercise-2 & 3
> ![image](https://github.com/user-attachments/assets/fedd1e65-6da1-4dc1-b9c3-ad1e2b8f21a3)
> ##### Exercise-4
> ![image](https://github.com/user-attachments/assets/71196633-75a3-4ead-b33b-21cdd6eafd2f)
> 

### Cáº¤U TRÃšC THÆ¯ Má»¤C Äá»‚ CHáº Y DAG AIRFLOW
```
data-engineering-practice-Le_Trung_Huu/
â”‚
â”œâ”€â”€ dags/                    â† ğŸ“‚ Chá»©a pipeline_dag.py
â”‚   â””â”€â”€ pipeline_dag.py  
â”‚
â”œâ”€â”€ Exercises/                   â† ğŸ“‚ Chá»©a cÃ¡c bÃ i táº­p vá»›i Dockerfile riÃªng
â”‚   â”œâ”€â”€ Exercise-1/
â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”œâ”€â”€ Exercise-2/
â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”œâ”€â”€ Exercise-3/
â”‚   â”œâ”€â”€ Exercise-4/
â”‚   â””â”€â”€ Exercise-5/
â”‚
â”œâ”€â”€ pipeline.py                  â† ğŸ“„ Code pipeline gá»‘c náº¿u muá»‘n gá»i ngoÃ i Airflow
â””â”€â”€ requirements.txt
â””â”€â”€ docker-compose.yml       â† âœ… Cháº¡y trong thÆ° má»¥c nÃ y
â””â”€â”€ Dockerfile
```
#### Dockerfile
```
FROM python:3.10-slim

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
RUN pip install --no-cache-dir -r requirements.txt

# Sao chÃ©p mÃ£ nguá»“n tá»« thÆ° má»¥c hiá»‡n táº¡i vÃ o trong container
COPY . /app

WORKDIR /app

# Lá»‡nh cháº¡y khi container Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng
CMD ["python", "main.py"]
```
#### Docker-compose:
```
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network

  airflow-init:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    entrypoint: bash -c "
      airflow db init && \
      airflow users create \
        --username airflow \
        --password airflow \
        --firstname Air \
        --lastname Flow \
        --role Admin \
        --email airflow@example.com
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'True'
    ports:
      - "8080:8080"
    command: ["airflow", "webserver"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: ["airflow", "scheduler"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  pgadmin:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - postgres
    networks:
      - app-network

volumes:
  postgres-db-volume:

networks:
  app-network:
    driver: bridge

#docker-compose up airflow-init
```

#### Pipeline-dag.py
```
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import os
import subprocess

default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
}

def run_main_py(path):
    print(f"ğŸ” Äang cháº¡y: {path}")
    result = subprocess.run(["python", path], capture_output=True, text=True)
    print("ğŸ“„ STDOUT:", result.stdout)
    print("â— STDERR:", result.stderr)
    result.check_returncode()

with DAG(
    dag_id='exercise_main_pipeline',
    default_args=default_args,
    description='Cháº¡y táº¥t cáº£ cÃ¡c main.py trong má»—i Exercise hÃ ng ngÃ y lÃºc 10h sÃ¡ng',
    schedule_interval='0 10 * * *',  # 10:00 UTC má»—i ngÃ y
    start_date=datetime(2025, 4, 25),
    catchup=False,
    tags=["exercise"],
) as dag:

    exercises_dir = "/opt/airflow/Exercises"

    if not os.path.exists(exercises_dir):
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: {exercises_dir}")

    previous_task = None

    for ex in sorted(os.listdir(exercises_dir)):
        ex_path = os.path.join(exercises_dir, ex, "main.py")
        if os.path.isfile(ex_path):
            task = PythonOperator(
                task_id=f'run_{ex.lower()}',
                python_callable=run_main_py,
                op_args=[ex_path],
            )
            if previous_task:
                previous_task >> task
            previous_task = task
```

### Káº¾T QUáº¢ SAU KHI CHáº Y DAG
>![image](https://github.com/user-attachments/assets/749ac8e5-5aea-428b-b2b4-df0cf866040c)

> ![image](https://github.com/user-attachments/assets/b889a380-7201-49db-af30-2384068a9653)
>![image](https://github.com/user-attachments/assets/5c9d74f3-9391-4b29-8a4a-6bc10718b474)
