# REPORT - LAB 9: ULTIMATE PRACTICE
## MÃ”N: NHáº¬P MÃ”N Ká»¸ THUáº¬T Dá»® LIá»†U - Lá»šP: DHKHDL19A
## Danh sÃ¡ch thÃ nh viÃªn:
>> 1. BÃ¹i Quang ThÃ nh
>> 2. Nguyá»…n Thá»‹ PhÆ°Æ¡ng Tháº£o
>> 3. TrÆ°Æ¡ng Äáº·ng HoÃ ng Tuyáº¿n

# BÃ€I LÃ€M
> 1. ÄÄƒng nháº­p vÃ o tÃ i khoáº£ng Github

> 2. Truy cáº­p vÃ o link:
> 
> 3. Chá»n fork
![image](https://github.com/user-attachments/assets/78bc5f7e-3354-46d3-93ae-37df89da9613)

> 4. Click Create fork
![image](https://github.com/user-attachments/assets/bf0a8369-8568-401f-a337-7457d2c25a3b)

## EXERCISE 1

> 1. Thá»±c thi lá»‡nh sau trong CMD: git clone Ä‘á»ƒ clone GitHub repo vá» mÃ¡y cá»§a mÃ¬nh
![image](https://github.com/user-attachments/assets/03a1821e-dd25-4748-931d-afee36e47d7e).

> 2. Sau Ä‘Ã³ tiáº¿n hÃ nh cháº¡y lá»‡nh `cd data-engineering-practice/Exercises/Exercise-1` Ä‘á»ƒ thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c Exercise-1

> 3. Tiáº¿p tá»¥c thá»±c hiá»‡n lá»‡nh: `docker build --tag=exercise-1 .` Ä‘á»ƒ build Docker image QuÃ¡ trÃ¬nh sáº½ máº¥t vÃ i phÃºt
![70fb32a899772b297266](https://github.com/user-attachments/assets/250e5f8f-4bf3-4263-b32d-9832969553f4)
![3c90cf92794dcb13925c](https://github.com/user-attachments/assets/9e3bd508-8290-41bf-8e1a-6223464211c3)
![7a5be3c75018e246bb09](https://github.com/user-attachments/assets/ee05f4d0-72e5-4105-8326-aef28a6f8d41)


> 4. Sá»­ dá»¥ng Visual Ä‘á»ƒ cháº¡y main.py
![c7929cded400665e3f11](https://github.com/user-attachments/assets/e9934529-5d0d-4e97-985f-69e06a9041eb)


> ##### Code sá»­ dá»¥ng cho main.py
```
# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
import os               # LÃ m viá»‡c vá»›i há»‡ thá»‘ng file (táº¡o thÆ° má»¥c, Ä‘Æ°á»ng dáº«n, xÃ³a file)
import requests         # Gá»­i HTTP request Ä‘á»ƒ táº£i file tá»« Internet
import zipfile          # Giáº£i nÃ©n cÃ¡c file .zip

# Danh sÃ¡ch cÃ¡c URL chá»©a dá»¯ liá»‡u cáº§n táº£i xuá»‘ng
download_uris = [
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2018_Q4.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q1.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q2.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q3.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2019_Q4.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2020_Q1.zip",
    "https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_2220_Q1.zip",  # URL sai Ä‘á»ƒ kiá»ƒm tra báº¯t lá»—i
]

# ThÆ° má»¥c lÆ°u file sau khi táº£i vÃ  giáº£i nÃ©n
DOWNLOAD_DIR = "downloads"

# HÃ m xá»­ lÃ½ táº£i xuá»‘ng vÃ  giáº£i nÃ©n má»™t file
def download_and_extract(url):
    # Láº¥y tÃªn file tá»« URL (vd: Divvy_Trips_2019_Q1.zip)
    filename = url.split("/")[-1]
    zip_path = os.path.join(DOWNLOAD_DIR, filename)  # ÄÆ°á»ng dáº«n lÆ°u file .zip

    try:
        print(f"Downloading: {filename}")

        # Gá»­i GET request Ä‘áº¿n URL
        response = requests.get(url)
        response.raise_for_status()  # Náº¿u lá»—i HTTP (vd: 404, 403) sáº½ raise exception

        # Ghi ná»™i dung táº£i Ä‘Æ°á»£c vÃ o file .zip
        with open(zip_path, "wb") as f:
            f.write(response.content)

        # Má»Ÿ file .zip vÃ  giáº£i nÃ©n táº¥t cáº£ ná»™i dung vÃ o thÆ° má»¥c DOWNLOAD_DIR
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(DOWNLOAD_DIR)

        # XÃ³a file .zip sau khi giáº£i nÃ©n thÃ nh cÃ´ng
        os.remove(zip_path)

        print(f"âœ“ Done: {filename}")

    # Báº¯t lá»—i HTTP (URL lá»—i, khÃ´ng tá»“n táº¡i...)
    except requests.exceptions.HTTPError as http_err:
        print(f"âŒ HTTP error for {filename}: {http_err}")

    # Báº¯t lá»—i náº¿u file táº£i vá» khÃ´ng pháº£i file zip há»£p lá»‡
    except zipfile.BadZipFile:
        print(f"âŒ Not a valid zip file: {filename}")

    # Báº¯t cÃ¡c lá»—i khÃ¡c
    except Exception as e:
        print(f"âŒ Failed {filename}: {e}")

# HÃ m main Ä‘iá»u phá»‘i quÃ¡ trÃ¬nh
def main():
    # Táº¡o thÆ° má»¥c "downloads" náº¿u chÆ°a tá»“n táº¡i
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)

    # Láº·p qua tá»«ng URL trong danh sÃ¡ch vÃ  xá»­ lÃ½
    for url in download_uris:
        download_and_extract(url)

# Khi cháº¡y script trá»±c tiáº¿p, gá»i hÃ m main
if __name__ == "__main__":
    main()

```
> Äoáº¡n code trÃªn thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥: 
- Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i

- Táº£i tá»«ng file tá»« danh sÃ¡ch download\_uris

- Giá»¯ tÃªn gá»‘c cá»§a file tá»« URL

- Giáº£i nÃ©n .zip thÃ nh .csv

- XÃ³a file .zip sau khi giáº£i nÃ©n

- Bá» qua URL khÃ´ng há»£p lá»‡ (vÃ­ dá»¥: cÃ¡i Divvy\_Trips\_2220\_Q1.zip khÃ´ng tá»“n táº¡i)

> 5. Sau khi save `main.py`, cháº¡y lá»‡nh `docker-compose up run` (máº¥t khoáº£ng 5 phÃºt)
![bada83a1af7f1d21446e](https://github.com/user-attachments/assets/0c8b5d85-dd88-486c-b4bf-f1f9ccfa7eab)


## EXERCISE 2

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-2`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-2 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![1504b98db053020d5b42](https://github.com/user-attachments/assets/734aab65-dc74-4c71-ab0f-d5de198ec074)

> 3. Sau khi build xong, truy cáº­p file main.py báº±ng VS code


##### Ná»™i dung file main.py

```import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

# URL cá»§a trang web chá»©a cÃ¡c tá»‡p cáº§n táº£i
BASE_URL = "https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/"

# Dáº¥u thá»i gian cáº§n tÃ¬m kiáº¿m trÃªn trang web
TARGET_TIMESTAMP = "2024-01-19 10:27"

def find_target_file():
    """
    HÃ m nÃ y sáº½ duyá»‡t qua trang web, tÃ¬m kiáº¿m tá»‡p vá»›i dáº¥u thá»i gian
    TARGET_TIMESTAMP vÃ  tráº£ vá» tÃªn tá»‡p tÆ°Æ¡ng á»©ng.
    """
    response = requests.get(BASE_URL)  # Gá»­i yÃªu cáº§u GET tá»›i trang web
    response.raise_for_status()  # Kiá»ƒm tra náº¿u yÃªu cáº§u thÃ nh cÃ´ng

    soup = BeautifulSoup(response.text, 'lxml')  # PhÃ¢n tÃ­ch trang HTML

    # TÃ¬m táº¥t cáº£ cÃ¡c dÃ²ng trong báº£ng
    rows = soup.find_all("tr")

    for row in rows:
        cols = row.find_all("td")  # TÃ¬m cÃ¡c Ã´ trong dÃ²ng
        if len(cols) >= 2:
            timestamp = cols[1].text.strip()  # Láº¥y dáº¥u thá»i gian
            if timestamp == TARGET_TIMESTAMP:
                filename = cols[0].text.strip()  # Láº¥y tÃªn tá»‡p
                return filename  # Tráº£ vá» tÃªn tá»‡p náº¿u tÃ¬m tháº¥y

    # Náº¿u khÃ´ng tÃ¬m tháº¥y tá»‡p vá»›i dáº¥u thá»i gian yÃªu cáº§u
    raise Exception(f"File with timestamp {TARGET_TIMESTAMP} not found.")

def download_file(filename):
    """
    HÃ m nÃ y sáº½ táº£i tá»‡p tá»« URL vÃ  lÆ°u tá»‡p vÃ o thÆ° má»¥c 'downloads'.
    """
    download_url = BASE_URL + filename  # XÃ¢y dá»±ng URL Ä‘áº§y Ä‘á»§ Ä‘á»ƒ táº£i tá»‡p
    local_path = os.path.join("downloads", filename)  # ÄÆ°á»ng dáº«n lÆ°u tá»‡p

    # Táº¡o thÆ° má»¥c 'downloads' náº¿u chÆ°a tá»“n táº¡i
    os.makedirs("downloads", exist_ok=True)

    # Gá»­i yÃªu cáº§u GET Ä‘á»ƒ táº£i tá»‡p
    response = requests.get(download_url)
    response.raise_for_status()  # Kiá»ƒm tra náº¿u yÃªu cáº§u thÃ nh cÃ´ng

    # LÆ°u tá»‡p vÃ o há»‡ thá»‘ng
    with open(local_path, 'wb') as f:
        f.write(response.content)
    print(f"Downloaded file to {local_path}")  # ThÃ´ng bÃ¡o tá»‡p Ä‘Ã£ Ä‘Æ°á»£c táº£i
    return local_path  # Tráº£ vá» Ä‘Æ°á»ng dáº«n cá»§a tá»‡p táº£i vá»

def analyze_file(filepath):
    """
    HÃ m nÃ y sáº½ má»Ÿ tá»‡p CSV, tÃ¬m báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t vÃ  in ra.
    """
    df = pd.read_csv(filepath)  # Äá»c tá»‡p CSV vÃ o DataFrame cá»§a Pandas

    # Kiá»ƒm tra xem cá»™t 'HourlyDryBulbTemperature' cÃ³ tá»“n táº¡i khÃ´ng
    if 'HourlyDryBulbTemperature' not in df.columns:
        raise Exception("'HourlyDryBulbTemperature' column not found in the file.")  # Náº¿u khÃ´ng cÃ³, nÃ©m lá»—i

    # Chuyá»ƒn Ä‘á»•i cá»™t 'HourlyDryBulbTemperature' thÃ nh kiá»ƒu sá»‘ (náº¿u cáº§n)
    df['HourlyDryBulbTemperature'] = pd.to_numeric(df['HourlyDryBulbTemperature'], errors='coerce')

    # TÃ¬m giÃ¡ trá»‹ nhiá»‡t Ä‘á»™ cao nháº¥t
    max_temp = df['HourlyDryBulbTemperature'].max()
    # Lá»c ra cÃ¡c báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t
    hottest_records = df[df['HourlyDryBulbTemperature'] == max_temp]

    print("\nğŸŒ¡ Records with the highest HourlyDryBulbTemperature:")
    print(hottest_records)  # In ra cÃ¡c báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t

def main():
    """
    HÃ m chÃ­nh sáº½ gá»i cÃ¡c hÃ m trÃªn Ä‘á»ƒ tÃ¬m kiáº¿m tá»‡p, táº£i tá»‡p vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u.
    """
    try:
        print("Looking for file...")  # ThÃ´ng bÃ¡o Ä‘ang tÃ¬m kiáº¿m tá»‡p
        filename = find_target_file()  # TÃ¬m tá»‡p vá»›i dáº¥u thá»i gian cáº§n tÃ¬m

        print(f"Found file: {filename}")  # ThÃ´ng bÃ¡o tÃ¬m tháº¥y tá»‡p
        filepath = download_file(filename)  # Táº£i tá»‡p vá»

        print("Analyzing file...")  # ThÃ´ng bÃ¡o Ä‘ang phÃ¢n tÃ­ch tá»‡p
        analyze_file(filepath)  # PhÃ¢n tÃ­ch tá»‡p Ä‘á»ƒ tÃ¬m báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t

    except Exception as e:
        print(f"Error: {e}")  # In ra lá»—i náº¿u cÃ³

# Cháº¡y hÃ m main náº¿u tá»‡p nÃ y Ä‘Æ°á»£c thá»±c thi trá»±c tiáº¿p
if __name__ == "__main__":
    main()

```

> 4. Sau khi save file main.py, cháº¡y dÃ²ng lá»‡nh `docker-compose up run`

> 5. Káº¿t quáº£ thu Ä‘Æ°á»£c
> ![8800406e25b797e9cea6](https://github.com/user-attachments/assets/3b78c261-28a4-4f6a-986c-dab636f84045)

## EXERCISE 3

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-3`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-3 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/19b9503f-2c9b-4fcc-8476-1dfcb0a388a9)


> 3. Sau khi build xong, truy cáº­p file `main.py` báº±ng VS code

##### Code sá»­ dá»¥ng cho main.py:
```
import requests
import gzip
import io
import sys # Äá»ƒ ghi trá»±c tiáº¿p ra stdout, Ä‘Ã´i khi há»¯u Ã­ch cho streaming

# URL gá»‘c cá»§a Common Crawl
COMMON_CRAWL_BASE_URL = 'https://data.commoncrawl.org'

def download_file(url):
    """Táº£i tá»‡p tá»« URL vÃ  tráº£ vá» ná»™i dung"""
    print(f"Äang táº£i tá»‡p tá»« URL: {url}")
    try:
        response = requests.get(url)
        response.raise_for_status()  # PhÃ¡t sinh ngoáº¡i lá»‡ náº¿u status code khÃ´ng pháº£i 2xx
        return response.content
    except requests.exceptions.RequestException as e:
        print(f"ÄÃ£ xáº£y ra lá»—i khi táº£i tá»‡p: {e}", file=sys.stderr)
        raise

def s3_uri_to_http_url(uri):
    """Chuyá»ƒn Ä‘á»•i S3 URI hoáº·c Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i thÃ nh URL HTTP cho Common Crawl"""
    if uri.startswith('s3://'):
        s3_path = uri[len('s3://'):]
        # Bá» qua pháº§n bucket (thÆ°á»ng lÃ  'commoncrawl')
        path = s3_path[s3_path.find('/') + 1:]
        return f"{COMMON_CRAWL_BASE_URL}/{path}"
    else:
        # Náº¿u lÃ  Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i, sá»­ dá»¥ng trá»±c tiáº¿p
        return f"{COMMON_CRAWL_BASE_URL}/{uri}"

def main():
    # --- Äá»‹nh nghÄ©a cÃ¡c tham sá»‘ ---
    # URL cá»§a tá»‡p wet.paths.gz
    WET_PATHS_URL = f"{COMMON_CRAWL_BASE_URL}/crawl-data/CC-MAIN-2022-05/wet.paths.gz"

    print(f"--- Báº¯t Ä‘áº§u xá»­ lÃ½ dá»¯ liá»‡u Common Crawl ---")

    try:
        # --- BÆ°á»›c 1: Táº£i tá»‡p .gz ban Ä‘áº§u ---
        print(f"1. Äang táº£i tá»‡p wet.paths.gz tá»« {WET_PATHS_URL}")
        gz_content = download_file(WET_PATHS_URL)
        print(f"   ÄÃ£ táº£i xong {len(gz_content)} bytes.")

        # --- BÆ°á»›c 2: Giáº£i nÃ©n vÃ  Ä‘á»c tá»‡p .gz ---
        print(f"2. Äang giáº£i nÃ©n vÃ  Ä‘á»c dÃ²ng Ä‘áº§u tiÃªn...")
        with gzip.GzipFile(fileobj=io.BytesIO(gz_content), mode='rb') as gz_file:
            wet_uri = gz_file.readline().decode('utf-8').strip()

        print(f"   DÃ²ng Ä‘áº§u tiÃªn (URI tá»‡p WET) lÃ : {wet_uri}")

        # --- BÆ°á»›c 3: Chuyá»ƒn Ä‘á»•i S3 URI thÃ nh URL HTTP ---
        wet_url = s3_uri_to_http_url(wet_uri)
        print(f"3. URL cá»§a tá»‡p WET: {wet_url}")

        # --- BÆ°á»›c 4: Táº£i tá»‡p WET vÃ  xá»­ lÃ½ ---
        print(f"4. Äang táº£i tá»‡p WET...")
        wet_content = download_file(wet_url)
        print(f"   ÄÃ£ táº£i tá»‡p WET thÃ nh cÃ´ng ({len(wet_content)} bytes).")

        # --- BÆ°á»›c 5: Xá»­ lÃ½ vÃ  hiá»ƒn thá»‹ ná»™i dung tá»‡p WET ---
        print(f"5. Ná»™i dung cá»§a tá»‡p WET:")
        wet_fileobj = io.BytesIO(wet_content)
        # WET files are gzipped, so we need to decompress them
        with gzip.GzipFile(fileobj=wet_fileobj, mode='rb') as wet_file:
            line_count = 0
            for line in wet_file:
                decoded_line = line.decode('utf-8', errors='replace').rstrip('\r\n')
                print(decoded_line)
                line_count += 1
                # Giá»›i háº¡n sá»‘ dÃ²ng hiá»ƒn thá»‹ Ä‘á»ƒ trÃ¡nh quÃ¡ nhiá»u Ä‘áº§u ra
                if line_count >= 100:
                    print("... (cÃ²n nhiá»u dÃ²ng khÃ¡c)")
                    break

        print(f"   ÄÃ£ hiá»ƒn thá»‹ {line_count} dÃ²ng tá»« tá»‡p WET.")
        print(f"--- HoÃ n thÃ nh xá»­ lÃ½ ---")

    except Exception as e:
        print(f"ÄÃ£ xáº£y ra lá»—i: {e}", file=sys.stderr)
        sys.exit(1)  # ThoÃ¡t vá»›i mÃ£ lá»—i Ä‘á»ƒ bÃ¡o hiá»‡u tháº¥t báº¡i


if __name__ == "__main__":
    main()

```
> 4. Sau khi lÆ°u file `main.py`, thá»±c hiá»‡n lá»‡nh `docker-compose up run`
> 5. Káº¿t quáº£ sau khi thá»±c hiá»‡n
> ![image](https://github.com/user-attachments/assets/fc59b0b3-f477-43cc-9d15-0f07215786a1)



## EXERCISE-4

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-4`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-4 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/086ebd6b-8fb8-4996-8b61-ea52b64207b7)


> 3. Ná»™i dung file `main.py`
```
import json
import csv
import glob
import os

def flatten_json(json_obj, parent_key='', sep='_'):
    """
    LÃ m pháº³ng má»™t Ä‘á»‘i tÆ°á»£ng JSON cÃ³ cáº¥u trÃºc lá»“ng nhau.
    
    Args:
        json_obj: Äá»‘i tÆ°á»£ng JSON cáº§n lÃ m pháº³ng
        parent_key: KhÃ³a cha (sá»­ dá»¥ng Ä‘á»ƒ Ä‘á»‡ quy)
        sep: KÃ½ tá»± phÃ¢n tÃ¡ch giá»¯a khÃ³a cha vÃ  con
    
    Returns:
        dict: Dictionary Ä‘Ã£ Ä‘Æ°á»£c lÃ m pháº³ng
    """
    flattened = {}
    
    # Duyá»‡t qua táº¥t cáº£ cÃ¡c cáº·p key-value trong json_obj
    for key, value in json_obj.items():
        # Táº¡o tÃªn khÃ³a má»›i báº±ng cÃ¡ch ná»‘i khÃ³a cha vÃ  khÃ³a hiá»‡n táº¡i
        new_key = f"{parent_key}{sep}{key}" if parent_key else key
        
        # Náº¿u giÃ¡ trá»‹ lÃ  tá»« Ä‘iá»ƒn (dict), gá»i Ä‘á»‡ quy Ä‘á»ƒ lÃ m pháº³ng nÃ³
        if isinstance(value, dict):
            # Cáº­p nháº­t flattened vá»›i káº¿t quáº£ tá»« hÃ m Ä‘á»‡ quy
            flattened.update(flatten_json(value, new_key, sep))
        else:
            # Náº¿u khÃ´ng pháº£i dict, gÃ¡n giÃ¡ trá»‹ trá»±c tiáº¿p
            flattened[new_key] = value
    
    return flattened

def json_to_csv(json_file_path, csv_file_path):
    """
    Chuyá»ƒn Ä‘á»•i má»™t file JSON thÃ nh file CSV.
    
    Args:
        json_file_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file JSON
        csv_file_path: ÄÆ°á»ng dáº«n Ä‘á»ƒ lÆ°u file CSV
    """
    print(f"Äang chuyá»ƒn Ä‘á»•i {json_file_path} -> {csv_file_path}")
    
    # Äá»c file JSON
    with open(json_file_path, 'r') as json_file:
        json_data = json.load(json_file)
    
    # LÃ m pháº³ng JSON
    flattened_data = flatten_json(json_data)
    
    # Láº¥y táº¥t cáº£ cÃ¡c khÃ³a Ä‘á»ƒ lÃ m tiÃªu Ä‘á» cho CSV
    fieldnames = flattened_data.keys()
    
    # Ghi ra file CSV
    with open(csv_file_path, 'w', newline='') as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
        writer.writeheader()  # Viáº¿t dÃ²ng tiÃªu Ä‘á»
        writer.writerow(flattened_data)  # Viáº¿t dÃ²ng dá»¯ liá»‡u

def main():
    """
    HÃ m chÃ­nh thá»±c hiá»‡n cÃ¡c bÆ°á»›c xá»­ lÃ½:
    1. TÃ¬m táº¥t cáº£ file JSON trong thÆ° má»¥c data
    2. Chuyá»ƒn Ä‘á»•i chÃºng thÃ nh file CSV
    """
    # ÄÆ°á»ng dáº«n gá»‘c Ä‘áº¿n thÆ° má»¥c data
    data_dir = 'data'
    
    # TÃ¬m táº¥t cáº£ file .json trong data_dir vÃ  táº¥t cáº£ thÆ° má»¥c con cá»§a nÃ³
    # ** nghÄ©a lÃ  tÃ¬m kiáº¿m Ä‘á»‡ quy trong táº¥t cáº£ cÃ¡c thÆ° má»¥c con
    # *.json nghÄ©a lÃ  tÃ¬m táº¥t cáº£ cÃ¡c file cÃ³ Ä‘uÃ´i .json
    json_files = glob.glob(os.path.join(data_dir, '**', '*.json'), recursive=True)
    
    print(f"Danh sÃ¡ch file JSON tÃ¬m tháº¥y bá»Ÿi glob: {json_files}")
    
    print(f"ÄÃ£ tÃ¬m tháº¥y {len(json_files)} file JSON:")
    for file in json_files:
        print(f"  - {file}")
    
    # Duyá»‡t qua tá»«ng file JSON vÃ  chuyá»ƒn Ä‘á»•i nÃ³ thÃ nh CSV
    for json_file in json_files:
        # Táº¡o tÃªn file CSV tá»« tÃªn file JSON (thay Ä‘uÃ´i .json thÃ nh .csv)
        csv_file = json_file.replace('.json', '.csv')
        
        # Gá»i hÃ m Ä‘á»ƒ chuyá»ƒn Ä‘á»•i
        json_to_csv(json_file, csv_file)
    
    print("\nHoÃ n táº¥t chuyá»ƒn Ä‘á»•i!")

if __name__ == "__main__":
    main()
```

> 4. Sau khi save file ` main.py`, thá»±c thi lá»‡nh `docker-compose up run`
> 5. Káº¿t quáº£ sau khi thá»±c hiá»‡n:

![image](https://github.com/user-attachments/assets/51311436-0077-4ad4-af9c-9c9cb91bae90)

![image](https://github.com/user-attachments/assets/da9d720a-35b7-4a8d-9908-ba14146c8f8e)

![image](https://github.com/user-attachments/assets/188b1474-9f76-412d-87a9-68dab9ab4110)


## EXERCISE-5

> 1.Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-5`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-5 .` Ä‘á»ƒ build image Docker
> ![image](https://github.com/user-attachments/assets/b75fd14b-9a7b-4de5-a087-e1dd36bdca41)


#### Ná»™i dung file main.py:
```
import psycopg2  # ThÆ° viá»‡n Ä‘á»ƒ káº¿t ná»‘i vÃ  thao tÃ¡c vá»›i PostgreSQL
import csv       # Äá»c file CSV
import uuid      # ThÆ° viá»‡n táº¡o UUID (khÃ´ng dÃ¹ng trong Ä‘oáº¡n nÃ y nhÆ°ng cÃ³ thá»ƒ há»¯u Ã­ch sau)
from datetime import datetime  # Äá»ƒ xá»­ lÃ½ Ä‘á»‹nh dáº¡ng ngÃ y thÃ¡ng
import os        # Thao tÃ¡c vá»›i há»‡ thá»‘ng file

# HÃ m táº¡o cÃ¡c báº£ng trong cÆ¡ sá»Ÿ dá»¯ liá»‡u náº¿u chÆ°a tá»“n táº¡i
def create_tables(cur):
    # Táº¡o báº£ng 'accounts'
    cur.execute("""
        CREATE TABLE IF NOT EXISTS accounts (
            customer_id INT PRIMARY KEY,
            first_name VARCHAR(50),
            last_name VARCHAR(50),
            address_1 VARCHAR(100),
            address_2 VARCHAR(100),
            city VARCHAR(50),
            state VARCHAR(20),
            zip_code VARCHAR(10),
            join_date DATE
        );
    """)
    # Táº¡o index cho trÆ°á»ng 'last_name' Ä‘á»ƒ tÄƒng tá»‘c truy váº¥n
    cur.execute("CREATE INDEX IF NOT EXISTS idx_accounts_last_name ON accounts(last_name);")

    # Táº¡o báº£ng 'products'
    cur.execute("""
        CREATE TABLE IF NOT EXISTS products (
            product_id INT PRIMARY KEY,
            product_code INT,
            product_description VARCHAR(100)
        );
    """)
    # Táº¡o index cho trÆ°á»ng 'product_code'
    cur.execute("CREATE INDEX IF NOT EXISTS idx_products_code ON products(product_code);")

    # Táº¡o báº£ng 'transactions'
    cur.execute("""
        CREATE TABLE IF NOT EXISTS transactions (
            transaction_id TEXT PRIMARY KEY,
            transaction_date DATE,
            product_id INT REFERENCES products(product_id),
            product_code INT,
            product_description VARCHAR(100),
            quantity INT,
            account_id INT REFERENCES accounts(customer_id)
        );
    """)
    # Táº¡o index Ä‘á»ƒ tá»‘i Æ°u truy váº¥n trÃªn product_id vÃ  account_id
    cur.execute("CREATE INDEX IF NOT EXISTS idx_transactions_product_id ON transactions(product_id);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_transactions_account_id ON transactions(account_id);")


# HÃ m nháº­p dá»¯ liá»‡u tá»« cÃ¡c file CSV vÃ o database
def import_csv(cur, conn):
    base_path = os.path.join(os.path.dirname(__file__), "data")  # ÄÆ°á»ng dáº«n tá»›i thÆ° má»¥c 'data'

    # Nháº­p dá»¯ liá»‡u cho báº£ng 'accounts'
    with open(os.path.join(base_path, "accounts.csv"), newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            cur.execute("""
                INSERT INTO accounts (
                    customer_id, first_name, last_name, address_1, address_2,
                    city, state, zip_code, join_date
                ) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
                ON CONFLICT (customer_id) DO NOTHING;  -- Náº¿u trÃ¹ng khÃ³a chÃ­nh thÃ¬ bá» qua
            """, (
                int(row["customer_id"]),
                row["first_name"],
                row["last_name"],
                row["address_1"],
                row["address_2"] if row["address_2"] != "NaN" else None,  # Chuyá»ƒn 'NaN' thÃ nh None
                row["city"],
                row["state"],
                row["zip_code"],
                datetime.strptime(row["join_date"], "%Y/%m/%d").date()  # Chuyá»ƒn chuá»—i thÃ nh kiá»ƒu DATE
            ))
        conn.commit()  # LÆ°u thay Ä‘á»•i sau khi chÃ¨n xong

    # Nháº­p dá»¯ liá»‡u cho báº£ng 'products'
    with open(os.path.join(base_path, "products.csv"), newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            cur.execute("""
                INSERT INTO products (
                    product_id, product_code, product_description
                ) VALUES (%s, %s, %s)
                ON CONFLICT (product_id) DO NOTHING;
            """, (
                int(row["product_id"]),
                int(row["product_code"]),
                row["product_description"]
            ))
        conn.commit()

    # Nháº­p dá»¯ liá»‡u cho báº£ng 'transactions'
    with open(os.path.join(base_path, "transactions.csv"), newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            cur.execute("""
                INSERT INTO transactions (
                    transaction_id, transaction_date, product_id, product_code,
                    product_description, quantity, account_id
                ) VALUES (%s,%s,%s,%s,%s,%s,%s)
                ON CONFLICT (transaction_id) DO NOTHING;
            """, (
                row["transaction_id"],
                datetime.strptime(row["transaction_date"], "%Y/%m/%d").date(),
                int(row["product_id"]),
                int(row["product_code"]),
                row["product_description"],
                int(row["quantity"]),
                int(row["account_id"])
            ))
        conn.commit()


# HÃ m chÃ­nh Ä‘á»ƒ cháº¡y toÃ n bá»™ chÆ°Æ¡ng trÃ¬nh
def main():
    # ThÃ´ng tin káº¿t ná»‘i tá»›i database
    host = "postgres"
    database = "postgres"
    user = "postgres"
    pas = "postgres"
    conn = psycopg2.connect(host=host, database=database, user=user, password=pas)
    cur = conn.cursor()

    # Táº¡o báº£ng náº¿u chÆ°a cÃ³
    create_tables(cur)
    conn.commit()

    # Nháº­p dá»¯ liá»‡u tá»« CSV
    import_csv(cur, conn)

    print("âœ… Tables created and CSV data imported successfully.")

    # ÄÃ³ng káº¿t ná»‘i
    cur.close()
    conn.close()


# Khi cháº¡y file trá»±c tiáº¿p thÃ¬ thá»±c hiá»‡n hÃ m main()
if __name__ == "__main__":
    main()

```

> 3. Sau khi lÆ°u láº¡i, thá»±c thi lá»‡nh `docker-compose up run`
> 4. Káº¿t quáº£ sau khi thá»±c hiá»‡n:
![image](https://github.com/user-attachments/assets/4625ce20-fb40-49e9-b9c0-be0f6bb9acbf)

> Truy váº¥n cÃ¡c báº£ng vá»«a táº¡o trong container posgres-1
![image](https://github.com/user-attachments/assets/e70ea051-15fc-4f1b-9cbd-0e3e85bf7830)

## PIPELINE Tá»° Äá»˜NG THá»°C HIá»†N BÃ€I Táº¬P 1- 5
#### Code cho pipeline.py:
```
import os
import subprocess

# List cÃ¡c Exercise báº¡n muá»‘n cháº¡y
exercises = ['Exercise-1', 'Exercise-2', 'Exercise-3', 'Exercise-4', 'Exercise-5']

# HÃ m kiá»ƒm tra xem image Ä‘Ã£ cÃ³ chÆ°a
def check_image_exists(image_name):
    result = subprocess.run(['docker', 'images', '-q', image_name], stdout=subprocess.PIPE)
    return result.stdout.decode().strip() != ''

# HÃ m build image náº¿u chÆ°a cÃ³
def build_image(exercise_name):
    print(f"Image {exercise_name} chÆ°a cÃ³, báº¯t Ä‘áº§u build...")
    result = subprocess.run(['docker', 'build', '-t', exercise_name, f'D:/NMKTDL/data-engineering-practice-main/Exercises/{exercise_name}'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print(f"Build image {exercise_name} tháº¥t báº¡i. Dá»«ng pipeline.")
        print(result.stderr.decode())
        exit(1)
    print(f"Build image {exercise_name} thÃ nh cÃ´ng.")

# HÃ m cháº¡y docker-compose
def run_docker_compose(exercise_name):
    print(f"Äang cháº¡y {exercise_name} báº±ng image {exercise_name}...")
    compose_file = f'D:/NMKTDL/data-engineering-practice-main/Exercises/{exercise_name}/docker-compose.yml'
    result = subprocess.run(['docker-compose', '-f', compose_file, 'up'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print(f"Lá»—i khi cháº¡y {exercise_name}. Dá»«ng pipeline.")
        print(result.stderr.decode())
        exit(1)
    
    # Kiá»ƒm tra logs cá»§a cÃ¡c container
    print("Kiá»ƒm tra logs cá»§a cÃ¡c container...")
    logs_result = subprocess.run(['docker-compose', '-f', compose_file, 'logs'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    print(logs_result.stdout.decode())  # In logs Ä‘á»ƒ xem chi tiáº¿t

    print(f"{exercise_name} Ä‘Ã£ hoÃ n táº¥t!")

# Pipeline
def run_pipeline():
    for exercise in exercises:
        # Kiá»ƒm tra image Ä‘Ã£ tá»“n táº¡i chÆ°a
        if not check_image_exists(exercise.lower()):
            build_image(exercise)
        else:
            print(f"Image {exercise} Ä‘Ã£ cÃ³ sáºµn.")
        
        # Cháº¡y docker-compose cho bÃ i
        run_docker_compose(exercise)

    print("\nPipeline hoÃ n táº¥t!")

if __name__ == "__main__":
    run_pipeline()
```
> #### Káº¿t quáº£ thá»±c hiá»‡n:
> ##### Exercise-1
> ![image](https://github.com/user-attachments/assets/63d6cecb-88f2-48c4-816d-1dfc4b767f61)
> ##### Exercise-2 & 3
> ![image](https://github.com/user-attachments/assets/fedd1e65-6da1-4dc1-b9c3-ad1e2b8f21a3)
> ##### Exercise-4
> ![image](https://github.com/user-attachments/assets/71196633-75a3-4ead-b33b-21cdd6eafd2f)
> 

### Cáº¤U TRÃšC THÆ¯ Má»¤C Äá»‚ CHáº Y DAG AIRFLOW
```
data-engineering-practice-Le_Trung_Huu/
â”‚
â”œâ”€â”€ dags/                    â† ğŸ“‚ Chá»©a pipeline_dag.py
â”‚   â””â”€â”€ pipeline_dag.py  
â”‚
â”œâ”€â”€ Exercises/                   â† ğŸ“‚ Chá»©a cÃ¡c bÃ i táº­p vá»›i Dockerfile riÃªng
â”‚   â”œâ”€â”€ Exercise-1/
â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”œâ”€â”€ Exercise-2/
â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”œâ”€â”€ Exercise-3/
â”‚   â”œâ”€â”€ Exercise-4/
â”‚   â””â”€â”€ Exercise-5/
â”‚
â”œâ”€â”€ pipeline.py                  â† ğŸ“„ Code pipeline gá»‘c náº¿u muá»‘n gá»i ngoÃ i Airflow
â””â”€â”€ requirements.txt
â””â”€â”€ docker-compose.yml       â† âœ… Cháº¡y trong thÆ° má»¥c nÃ y
â””â”€â”€ Dockerfile
```
#### Dockerfile
```
FROM python:3.10-slim

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
RUN pip install --no-cache-dir -r requirements.txt

# Sao chÃ©p mÃ£ nguá»“n tá»« thÆ° má»¥c hiá»‡n táº¡i vÃ o trong container
COPY . /app

WORKDIR /app

# Lá»‡nh cháº¡y khi container Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng
CMD ["python", "main.py"]
```
#### Docker-compose:
```
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network

  airflow-init:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    entrypoint: bash -c "
      airflow db init && \
      airflow users create \
        --username airflow \
        --password airflow \
        --firstname Air \
        --lastname Flow \
        --role Admin \
        --email airflow@example.com
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'True'
    ports:
      - "8080:8080"
    command: ["airflow", "webserver"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: ["airflow", "scheduler"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  pgadmin:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - postgres
    networks:
      - app-network

volumes:
  postgres-db-volume:

networks:
  app-network:
    driver: bridge

#docker-compose up airflow-init
```

#### Pipeline-dag.py
```
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import os
import subprocess

default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
}

def run_main_py(path):
    print(f"ğŸ” Äang cháº¡y: {path}")
    result = subprocess.run(["python", path], capture_output=True, text=True)
    print("ğŸ“„ STDOUT:", result.stdout)
    print("â— STDERR:", result.stderr)
    result.check_returncode()

with DAG(
    dag_id='exercise_main_pipeline',
    default_args=default_args,
    description='Cháº¡y táº¥t cáº£ cÃ¡c main.py trong má»—i Exercise hÃ ng ngÃ y lÃºc 10h sÃ¡ng',
    schedule_interval='0 10 * * *',  # 10:00 UTC má»—i ngÃ y
    start_date=datetime(2025, 4, 25),
    catchup=False,
    tags=["exercise"],
) as dag:

    exercises_dir = "/opt/airflow/Exercises"

    if not os.path.exists(exercises_dir):
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: {exercises_dir}")

    previous_task = None

    for ex in sorted(os.listdir(exercises_dir)):
        ex_path = os.path.join(exercises_dir, ex, "main.py")
        if os.path.isfile(ex_path):
            task = PythonOperator(
                task_id=f'run_{ex.lower()}',
                python_callable=run_main_py,
                op_args=[ex_path],
            )
            if previous_task:
                previous_task >> task
            previous_task = task
```

### Káº¾T QUáº¢ SAU KHI CHáº Y DAG
>![image](https://github.com/user-attachments/assets/749ac8e5-5aea-428b-b2b4-df0cf866040c)

> ![image](https://github.com/user-attachments/assets/b889a380-7201-49db-af30-2384068a9653)
>![image](https://github.com/user-attachments/assets/5c9d74f3-9391-4b29-8a4a-6bc10718b474)

> # REPORT - LAB 8:
## EXERCISE 1

> 1. Thá»±c thi lá»‡nh sau trong CMD: git clone Ä‘á»ƒ clone GitHub repo vá» mÃ¡y cá»§a mÃ¬nh
> ![649dabe12114934aca05](https://github.com/user-attachments/assets/d4b2284b-1f99-4733-95e8-388c142eeb00)


> 2. Sau Ä‘Ã³ tiáº¿n hÃ nh cháº¡y lá»‡nh `cd cd Build-data-warehouse-with-Airflow-Python-for-E-commerce

> 3. Tiáº¿p tá»¥c thá»±c hiá»‡n lá»‡nh: 'docker-compose up -d' Ä‘á»ƒ build Docker image QuÃ¡ trÃ¬nh sáº½ máº¥t vÃ i phÃºt
> ![Annotation 2025-05-06 211724](https://github.com/user-attachments/assets/44cda780-fdd2-4535-8973-e4596bcdad04)

> 4. Má»Ÿ Airflow Web UI Ä‘á»ƒ xem quÃ¡ trÃ¬nh cháº¡y
> Máº·c Ä‘á»‹nh, Airflow Web UI sáº½ cháº¡y táº¡i: http://localhost:8080
> ![Annotation 2025-05-06 215312](https://github.com/user-attachments/assets/81a636bf-8c9c-492a-a5f3-bab8aeffe751)
> ![image](https://github.com/user-attachments/assets/93b7b823-de6b-4931-9f7b-133ba179dcf9)
> 5. Check láº¡i trong dbeaver
> ![image](https://github.com/user-attachments/assets/733cbed6-c76c-44fa-8223-4d9a6f936319)
## EXERCISE 2

> 1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng lÃ m viá»‡c:

Táº¡o má»™t thÆ° má»¥c dá»± Ã¡n riÃªng biá»‡t trÃªn há»‡ thá»‘ng mÃ¡y tÃ­nh Ä‘á»ƒ chá»©a táº¥t cáº£ cÃ¡c file cáº¥u hÃ¬nh vÃ  mÃ£ nguá»“n liÃªn quan Ä‘áº¿n Airflow.

BÃªn trong thÆ° má»¥c dá»± Ã¡n, táº¡o má»™t thÆ° má»¥c con cÃ³ tÃªn lÃ  dags. ÄÃ¢y lÃ  nÆ¡i sáº½ chá»©a cÃ¡c file Ä‘á»‹nh nghÄ©a DAG cá»§a Airflow (cÃ¡c file .py).

Äáº·t cÃ¡c file Ä‘á»‹nh nghÄ©a DAG Ä‘Ã£ cÃ³ sáºµn (simple_dag_local.py, complex_dag_local.py, miai_dag.py, sensor_local.py) vÃ o thÆ° má»¥c dags vá»«a táº¡o.
![image](https://github.com/user-attachments/assets/a7fecc65-8c3d-4927-8225-db3aaef9fc20)


> 2. XÃ¢y dá»±ng file cáº¥u hÃ¬nh Docker Compose (docker-compose.yaml):

Táº¡o file docker-compose.yaml á»Ÿ thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n.

Cáº¥u hÃ¬nh cÃ¡c dá»‹ch vá»¥ cáº§n thiáº¿t Ä‘á»ƒ cháº¡y Airflow:

Dá»‹ch vá»¥ CÆ¡ sá»Ÿ dá»¯ liá»‡u (PostgreSQL): Äá»‹nh nghÄ©a má»™t dá»‹ch vá»¥ sá»­ dá»¥ng image PostgreSQL Ä‘á»ƒ lÃ m cÆ¡ sá»Ÿ dá»¯ liá»‡u lÆ°u trá»¯ metadata cá»§a Airflow. Cáº¥u hÃ¬nh tÃªn database, ngÆ°á»i dÃ¹ng vÃ  máº­t kháº©u phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a Airflow. Sá»­ dá»¥ng Docker Volume Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u database Ä‘Æ°á»£c lÆ°u trá»¯ bá»n vá»¯ng.

Dá»‹ch vá»¥ Airflow: Äá»‹nh nghÄ©a má»™t dá»‹ch vá»¥ sá»­ dá»¥ng image Apache Airflow. Cáº¥u hÃ¬nh dá»‹ch vá»¥ nÃ y Ä‘á»ƒ phá»¥ thuá»™c vÃ o dá»‹ch vá»¥ cÆ¡ sá»Ÿ dá»¯ liá»‡u, Ä‘áº£m báº£o database sáºµn sÃ ng trÆ°á»›c khi Airflow khá»Ÿi Ä‘á»™ng. Ãnh xáº¡ (mount) thÆ° má»¥c dags tá»« mÃ¡y host vÃ o thÆ° má»¥c DAGs bÃªn trong container Airflow. Cáº¥u hÃ¬nh cá»•ng (port) Ä‘á»ƒ truy cáº­p giao diá»‡n web cá»§a Airflow tá»« mÃ¡y host (máº·c Ä‘á»‹nh lÃ  8080).
code file docker-compose.yml:
```
# Sá»­ dá»¥ng phiÃªn báº£n Docker Compose
# Báº¡n cÃ³ thá»ƒ xÃ³a dÃ²ng version: '3' Ä‘á»ƒ trÃ¡nh cáº£nh bÃ¡o obsolete náº¿u muá»‘n
version: '3'

# Äá»‹nh nghÄ©a cÃ¡c dá»‹ch vá»¥ (services)
services:
  # Dá»‹ch vá»¥ cÆ¡ sá»Ÿ dá»¯ liá»‡u PostgreSQL cho Airflow metadata
  postgres:
    image: postgres:14 # Sá»­ dá»¥ng image PostgreSQL phiÃªn báº£n 14
    environment:
      # Cáº¥u hÃ¬nh thÃ´ng tin Ä‘Äƒng nháº­p vÃ  tÃªn database cho PostgreSQL
      # Airflow sáº½ sá»­ dá»¥ng database cÃ³ tÃªn 'airflow'
      - POSTGRES_USER=airflow # <-- TÃªn ngÆ°á»i dÃ¹ng database (cÃ³ thá»ƒ Ä‘á»•i)
      - POSTGRES_PASSWORD=airflow # <-- Máº­t kháº©u database (cÃ³ thá»ƒ Ä‘á»•i)
      - POSTGRES_DB=airflow # <-- TÃªn database mÃ  Airflow sáº½ káº¿t ná»‘i
    volumes:
      # LÆ°u trá»¯ dá»¯ liá»‡u cá»§a database vÃ o má»™t volume Ä‘á»ƒ dá»¯ liá»‡u khÃ´ng bá»‹ máº¥t khi container dá»«ng/xÃ³a
      - postgres_data:/var/lib/postgresql/data
    ports:
      # Ãnh xáº¡ cá»•ng 5432 cá»§a container ra cá»•ng 5432 trÃªn mÃ¡y host (tÃ¹y chá»n, há»¯u Ã­ch cho viá»‡c debug database)
      - "5432:5432"
    networks:
      # Káº¿t ná»‘i dá»‹ch vá»¥ nÃ y vÃ o máº¡ng ná»™i bá»™ 'airflow-network'
      - airflow-network
    healthcheck: # Kiá»ƒm tra tÃ¬nh tráº¡ng sá»©c khá»e cá»§a database
      test: [ "CMD", "pg_isready", "-U", "airflow" ] # Lá»‡nh kiá»ƒm tra
      interval: 5s # Kiá»ƒm tra má»—i 5 giÃ¢y
      retries: 5 # Thá»­ láº¡i 5 láº§n náº¿u lá»—i

  # Dá»‹ch vá»¥ Airflow
  airflow:
    image: apache/airflow:2.6.3 # Sá»­ dá»¥ng image Airflow phiÃªn báº£n 2.6.3
    depends_on:
      # Airflow phá»¥ thuá»™c vÃ o database, Ä‘áº£m báº£o postgres khá»Ÿi Ä‘á»™ng trÆ°á»›c
      postgres:
        condition: service_healthy # Chá» cho dá»‹ch vá»¥ postgres á»Ÿ tráº¡ng thÃ¡i healthy
    volumes:
      # Ãnh xáº¡ thÆ° má»¥c 'dags' trÃªn mÃ¡y host vÃ o thÆ° má»¥c DAGs bÃªn trong container Airflow
      # ÄÃ¢y lÃ  nÆ¡i báº¡n sáº½ Ä‘áº·t cÃ¡c file DAG cá»§a mÃ¬nh
      - ./dags:/opt/airflow/dags # <-- ThÆ° má»¥c DAGs trÃªn host : ThÆ° má»¥c DAGs trong container
      # Ãnh xáº¡ cÃ¡c thÆ° má»¥c khÃ¡c náº¿u DAG cá»§a báº¡n cáº§n Ä‘á»c/ghi file á»Ÿ ngoÃ i thÆ° má»¥c DAGs
      # VÃ­ dá»¥:
      # - ./data:/opt/airflow/data # ThÆ° má»¥c data cho Complex DAG
      # - ./stock_data:/opt/airflow/stock_data # ThÆ° má»¥c stock_data cho ML DAG
      # - ./models:/opt/airflow/models # ThÆ° má»¥c models cho ML DAG
      # - ./data_in:/opt/airflow/data_in # ThÆ° má»¥c input cho Sensor DAG
    ports:
      # Ãnh xáº¡ cá»•ng 8080 cá»§a webserver Airflow ra cá»•ng 8080 trÃªn mÃ¡y host
      - "8080:8080" # <-- Cá»•ng trÃªn host : Cá»•ng webserver trong container
    command: standalone # Cháº¡y Airflow á»Ÿ cháº¿ Ä‘á»™ standalone (bao gá»“m webserver vÃ  scheduler)
    environment:
      # Cáº¥u hÃ¬nh káº¿t ná»‘i database cho Airflow
      # Äáº£m báº£o thÃ´ng tin nÃ y khá»›p vá»›i thÃ´ng tin trong service postgres
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow # <-- ThÃ´ng tin káº¿t ná»‘i DB
      - AIRFLOW__CORE__LOAD_EXAMPLES=False # KhÃ´ng táº£i cÃ¡c DAG vÃ­ dá»¥ Ä‘i kÃ¨m Airflow
      # Cáº¥u hÃ¬nh mÃºi giá» (tÃ¹y chá»n)
      # - AIRFLOW__CFG__CORE__DEFAULT_TIMEZONE=Asia/Ho_Chi_Minh # <-- Äá»•i mÃºi giá» náº¿u cáº§n

      # TÄƒng thá»i gian timeout cho Gunicorn webserver
      - AIRFLOW__WEBSERVER__WEB_SERVER_MASTER_TIMEOUT=300 # <-- THÃŠM hoáº·c Sá»¬A dÃ²ng nÃ y, tÄƒng timeout lÃªn 300 giÃ¢y (5 phÃºt)

    networks:
      # Káº¿t ná»‘i dá»‹ch vá»¥ nÃ y vÃ o máº¡ng ná»™i bá»™ 'airflow-network'
      - airflow-network
    healthcheck: # Kiá»ƒm tra tÃ¬nh tráº¡ng sá»©c khá»e cá»§a Airflow webserver
      test: [ "CMD", "curl", "--fail", "-s", "http://localhost:8080/health" ] # Lá»‡nh kiá»ƒm tra
      interval: 30s # Kiá»ƒm tra má»—i 30 giÃ¢y
      timeout: 30s # Timeout sau 30 giÃ¢y
      retries: 5 # Thá»­ láº¡i 5 láº§n náº¿u lá»—i

# Äá»‹nh nghÄ©a máº¡ng ná»™i bá»™ cho cÃ¡c dá»‹ch vá»¥
networks:
  airflow-network:
    driver: bridge # Sá»­ dá»¥ng driver máº¡ng bridge

# Äá»‹nh nghÄ©a cÃ¡c volume Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u bá»n vá»¯ng
volumes:
  postgres_data: # Volume cho dá»¯ liá»‡u PostgreSQL

```

> 3. Táº¡o Dockerfile tÃ¹y chá»‰nh Ä‘á»ƒ cÃ i Ä‘áº·t Dependencies:

Táº¡o file Dockerfile á»Ÿ thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n.

Sá»­ dá»¥ng image Apache Airflow gá»‘c lÃ m ná»n (FROM apache/airflow:...).

ThÃªm cÃ¡c lá»‡nh RUN pip install Ä‘á»ƒ cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n Python bá»• sung mÃ  cÃ¡c file DAG phá»©c táº¡p cáº§n (vÃ­ dá»¥: pymysql, pandas, sendgrid, scikit-learn, tensorflow). Äiá»u nÃ y Ä‘áº£m báº£o cÃ¡c DAG cÃ³ thá»ƒ Ä‘Æ°á»£c import vÃ  cháº¡y mÃ  khÃ´ng gáº·p lá»—i thiáº¿u thÆ° viá»‡n.

Chá»‰nh sá»­a file docker-compose.yaml Ä‘á»ƒ dá»‹ch vá»¥ Airflow sá»­ dá»¥ng build: . thay vÃ¬ image: ..., chá»‰ Ä‘á»‹nh Docker Compose xÃ¢y dá»±ng image tá»« Dockerfile nÃ y.
code dockerfile:
```
# Sá»­ dá»¥ng image Airflow gá»‘c lÃ m ná»n
FROM apache/airflow:2.6.3

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n Python bá»• sung mÃ  cÃ¡c DAG cá»§a báº¡n cáº§n
# Dá»±a trÃªn cÃ¡c file DAG báº¡n cung cáº¥p, chÃºng ta cáº§n pymysql, pandas, sendgrid
# Báº¡n cÃ³ thá»ƒ thÃªm cÃ¡c thÆ° viá»‡n khÃ¡c vÃ o Ä‘Ã¢y náº¿u DAG cá»§a báº¡n cáº§n
RUN pip install --no-cache-dir \
    pymysql \
    pandas \
    sendgrid \
    scikit-learn \
    tensorflow
    # ThÃªm cÃ¡c thÆ° viá»‡n khÃ¡c náº¿u cáº§n, vÃ­ dá»¥:
    # scikit-learn \ # Cho miai_dag.py
    # tensorflow # Cho miai_dag.py

```

> 4. Khá»Ÿi Ä‘á»™ng mÃ´i trÆ°á»ng Airflow:

Má»Ÿ terminal hoáº·c command prompt vÃ  Ä‘iá»u hÆ°á»›ng Ä‘áº¿n thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n.

Cháº¡y lá»‡nh docker compose up -d --build. Lá»‡nh nÃ y sáº½:

Build image Docker tÃ¹y chá»‰nh cho dá»‹ch vá»¥ Airflow (bao gá»“m cáº£ viá»‡c cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n bá»• sung).

Táº£i image PostgreSQL (náº¿u chÆ°a cÃ³).

Táº¡o vÃ  khá»Ÿi Ä‘á»™ng cÃ¡c container cho dá»‹ch vá»¥ cÆ¡ sá»Ÿ dá»¯ liá»‡u vÃ  Airflow á»Ÿ cháº¿ Ä‘á»™ ná»n.

Táº¡o ngÆ°á»i dÃ¹ng quáº£n trá»‹ Ä‘áº§u tiÃªn:

Sau khi cÃ¡c container khá»Ÿi Ä‘á»™ng vÃ  dá»‹ch vá»¥ Airflow Ä‘Ã£ sáºµn sÃ ng (cÃ³ thá»ƒ máº¥t vÃ i phÃºt), sá»­ dá»¥ng lá»‡nh docker compose exec Ä‘á»ƒ cháº¡y lá»‡nh Airflow CLI bÃªn trong container Airflow nháº±m táº¡o ngÆ°á»i dÃ¹ng quáº£n trá»‹ Ä‘áº§u tiÃªn. Lá»‡nh cÃ³ dáº¡ng: docker compose exec airflow bash -c "airflow users create --username <tÃªn> --password <máº­t kháº©u> --firstname <tÃªn> --lastname <há»> --email <email> --role Admin".
![image](https://github.com/user-attachments/assets/35d865b8-644f-423d-83ae-ad476c307d85)
![image](https://github.com/user-attachments/assets/a107abdb-486b-4029-b60e-3cc07cdbbab0)
![image](https://github.com/user-attachments/assets/10fc7c4e-a329-450b-b8d7-8003a177d087)


> 5. Truy cáº­p giao diá»‡n web vÃ  kÃ­ch hoáº¡t DAGs:

Má»Ÿ trÃ¬nh duyá»‡t web vÃ  truy cáº­p Ä‘á»‹a chá»‰ http://localhost:8080.

ÄÄƒng nháº­p báº±ng thÃ´ng tin tÃ i khoáº£n quáº£n trá»‹ vá»«a táº¡o.

TrÃªn giao diá»‡n web, kiá»ƒm tra danh sÃ¡ch cÃ¡c DAG. CÃ¡c DAG Ä‘Ã£ copy vÃ o thÆ° má»¥c dags sáº½ xuáº¥t hiá»‡n.

KÃ­ch hoáº¡t (Unpause) cÃ¡c DAG mong muá»‘n báº±ng cÃ¡ch nháº¥n vÃ o nÃºt gáº¡t bÃªn cáº¡nh tÃªn DAG.
![image](https://github.com/user-attachments/assets/270c0a38-4637-4f1b-8a97-50c50608cf6e)

