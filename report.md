# REPORT - LAB 9: ULTIMATE PRACTICE
## MÃ”N: NHáº¬P MÃ”N Ká»¸ THUáº¬T Dá»® LIá»†U - Lá»šP: DHKHDL19A
## Danh sÃ¡ch thÃ nh viÃªn:
>> 1. Nguyá»…n Anh Huy
>> 2. LÃª Trung Há»¯u
>> 3. Huá»³nh Nháº­t HÃ o
>> 4. Tráº§n Nhá»±t HÃ o
>> 5. Phan Gia Huy

# BÃ€I LÃ€M
> 1. ÄÄƒng nháº­p vÃ o tÃ i khoáº£ng Github

> 2. Truy cáº­p vÃ o link:
> 
> 3. Chá»n fork
![image](https://github.com/user-attachments/assets/78bc5f7e-3354-46d3-93ae-37df89da9613)

> 4. Click Create fork
![image](https://github.com/user-attachments/assets/bf0a8369-8568-401f-a337-7457d2c25a3b)

## EXERCISE 1

> 1. Thá»±c thi lá»‡nh sau trong CMD: git clone Ä‘á»ƒ clone GitHub repo vá» mÃ¡y cá»§a mÃ¬nh
![image](https://github.com/user-attachments/assets/9d638ee5-8343-43e5-b3c9-7f08d1101a2f)

> 2. Sau Ä‘Ã³ tiáº¿n hÃ nh cháº¡y lá»‡nh `cd data-engineering-practice/Exercises/Exercise-1` Ä‘á»ƒ thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c Exercise-1

> 3. Tiáº¿p tá»¥c thá»±c hiá»‡n lá»‡nh: `docker build --tag=exercise-1 .` Ä‘á»ƒ build Docker image QuÃ¡ trÃ¬nh sáº½ máº¥t vÃ i phÃºt
![image](https://github.com/user-attachments/assets/852153d1-d493-47ea-b267-8a5b6843be07)
![image](https://github.com/user-attachments/assets/ebf1c936-ba6c-4796-8edc-a7ef97b8eaec)
![image](https://github.com/user-attachments/assets/1e3beb59-a0c5-4d13-9f90-209467c30530)

> 4. Sá»­ dá»¥ng Visual Ä‘á»ƒ cháº¡y main.py
![image](https://github.com/user-attachments/assets/2f38e384-09de-4d2d-aa2b-3f0613983592)

> ##### Code sá»­ dá»¥ng cho main.py
```
import os

import requests

import zipfile

download\_uris = [

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2018\_Q4.zip",

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2019\_Q1.zip",

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2019\_Q2.zip",

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2019\_Q3.zip",

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2019\_Q4.zip",

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2020\_Q1.zip",

Â  Â  "https://divvy-tripdata.s3.amazonaws.com/Divvy\_Trips\_2220\_Q1.zip",

]

def download\_and\_extract(url, download\_dir):

Â  Â  filename = url.split("/")[-1]

Â  Â  zip\_path = os.path.join(download\_dir, filename)

Â  Â  try:

Â  Â  Â  Â  print(f"Downloading: {filename}")

Â  Â  Â  Â  response = requests.get(url, timeout=10)

Â  Â  Â  Â  response.raise\_for\_status()

Â  Â  Â  Â  with open(zip\_path, "wb") as f:

Â  Â  Â  Â  Â  Â  f.write(response.content)

Â  Â  Â  Â  print(f"Extracting: {filename}")

Â  Â  Â  Â  with zipfile.ZipFile(zip\_path, 'r') as zip\_ref:

Â  Â  Â  Â  Â  Â  zip\_ref.extractall(download\_dir)

Â  Â  Â  Â  os.remove(zip\_path)

Â  Â  Â  Â  print(f"Finished: {filename}\n")

Â  Â  except requests.exceptions.HTTPError as http\_err:

Â  Â  Â  Â  print(f"HTTP error: {http\_err} â€” Skipping {filename}")

Â  Â  except zipfile.BadZipFile:

Â  Â  Â  Â  print(f"Bad zip file: {filename} â€” Skipping")

Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"Unexpected error: {e} â€” Skipping {filename}")

def main():

Â  Â  download\_dir = "downloads"

Â  Â  os.makedirs(download\_dir, exist\_ok=True)

Â  Â  for url in download\_uris:

Â  Â  Â  Â  download\_and\_extract(url, download\_dir)

if \_\_name\_\_ == "\_\_main\_\_":

Â  Â  main()
```
> Äoáº¡n code trÃªn thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥: 
- Táº¡o thÆ° má»¥c downloads náº¿u chÆ°a tá»“n táº¡i

- Táº£i tá»«ng file tá»« danh sÃ¡ch download\_uris

- Giá»¯ tÃªn gá»‘c cá»§a file tá»« URL

- Giáº£i nÃ©n .zip thÃ nh .csv

- XÃ³a file .zip sau khi giáº£i nÃ©n

- Bá» qua URL khÃ´ng há»£p lá»‡ (vÃ­ dá»¥: cÃ¡i Divvy\_Trips\_2220\_Q1.zip khÃ´ng tá»“n táº¡i)

> 5. Sau khi save `main.py`, cháº¡y lá»‡nh `docker-compose up run` (máº¥t khoáº£ng 5 phÃºt)
![image](https://github.com/user-attachments/assets/1937ba2e-ce1e-4977-a496-4767dd5d4ee6)

## EXERCISE 2

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-2`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-2 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/d3bb854c-f8e2-4a35-b4f8-dde609d5d8ff)

> 3. Sau khi build xong, truy cáº­p file main.py báº±ng VS code
> ![image](https://github.com/user-attachments/assets/6ade9a73-6976-4ba5-97c5-469a2b6efc5b)

##### Ná»™i dung file main.py

```
import requests

from bs4 import BeautifulSoup

import pandas as pd

import os

BASE\_URL = "https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/"

TARGET\_TIMESTAMP = "2024-01-19 10:27"

def find\_target\_file():

Â  Â  response = requests.get(BASE\_URL)

Â  Â  response.raise\_for\_status()

Â  Â  soup = BeautifulSoup(response.text, 'lxml')

Â  Â  rows = soup.find\_all("tr")

Â  Â  for row in rows:

Â  Â  Â  Â  cols = row.find\_all("td")

Â  Â  Â  Â  if len(cols) >= 2:

Â  Â  Â  Â  Â  Â  timestamp = cols[1].text.strip()

Â  Â  Â  Â  Â  Â  if timestamp == TARGET\_TIMESTAMP:

Â  Â  Â  Â  Â  Â  Â  Â  filename = cols[0].text.strip()

Â  Â  Â  Â  Â  Â  Â  Â  return filename

Â  Â  raise Exception("File with timestamp 2024-01-19 10:27 not found.")

def download\_file(filename):

Â  Â  download\_url = BASE\_URL + filename

Â  Â  local\_path = os.path.join("downloads", filename)

Â  Â  os.makedirs("downloads", exist\_ok=True)

Â  Â  response = requests.get(download\_url)

Â  Â  response.raise\_for\_status()

Â  Â  with open(local\_path, 'wb') as f:

Â  Â  Â  Â  f.write(response.content)

Â  Â  print(f"Downloaded file to {local\_path}")

Â  Â  return local\_path

def analyze\_file(filepath):

Â  Â  df = pd.read\_csv(filepath)

Â  Â  if 'HourlyDryBulbTemperature' not in df.columns:

Â  Â  Â  Â  raise Exception("'HourlyDryBulbTemperature' column not found in the file.")

Â  Â  # Chuyá»ƒn Ä‘á»•i nhiá»‡t Ä‘á»™ vá» kiá»ƒu sá»‘ (náº¿u cáº§n, vÃ¬ cÃ³ thá»ƒ lÃ  string)

Â  Â  df['HourlyDryBulbTemperature'] = pd.to\_numeric(df['HourlyDryBulbTemperature'], errors='coerce')

Â  Â  

Â  Â  max\_temp = df['HourlyDryBulbTemperature'].max()

Â  Â  hottest\_records = df[df['HourlyDryBulbTemperature'] == max\_temp]

Â  Â  print("\nRecords with the highest HourlyDryBulbTemperature:")

Â  Â  print(hottest\_records)

def main():

Â  Â  try:

Â  Â  Â  Â  print("Looking for file...")

Â  Â  Â  Â  filename = find\_target\_file()

Â  Â  Â  Â  print(f"Found file: {filename}")

Â  Â  Â  Â  filepath = download\_file(filename)

Â  Â  Â  Â  print("Analyzing file...")

Â  Â  Â  Â  analyze\_file(filepath)

Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"Error: {e}")

if \_\_name\_\_ == "\_\_main\_\_":

Â  Â  main()
```

> 4. Sau khi save file main.py, cháº¡y dÃ²ng lá»‡nh `docker-compose up run`

> 5. Káº¿t quáº£ thu Ä‘Æ°á»£c
> ![image](https://github.com/user-attachments/assets/ef39d0c0-2d63-40d6-b162-63a8d6f9552d)

## EXERCISE 3

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-3`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-3 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/b4dc7f5e-843b-4e94-810b-596e8595e37e)

> 3. Sau khi build xong, truy cáº­p file `main.py` báº±ng VS code

##### Code sá»­ dá»¥ng cho main.py:
```
import io
import gzip
import requests
from dotenv import load_dotenv

load_dotenv()
def download_file_from_url(url):
    response = requests.get(url)
    if response.status_code == 200:
        return response.content
    else:
        print(f"Error downloading file: {response.status_code}")
        return None
def main():
    url = 'https://data.commoncrawl.org/crawl-data/CC-MAIN-2022-05/wet.paths.gz'
    gz_content = download_file_from_url(url)
    
    if gz_content:
        with gzip.GzipFile(fileobj=io.BytesIO(gz_content)) as f:
            first_line = f.readline().decode('utf-8').strip() 
            print(f"First line from wet.paths.gz: {first_line}")
            uri = first_line
            print(f"Extracted URI: {uri}")
            print("\nPrinting the first 50 lines from wet.paths.gz:")
            for i, line in enumerate(f):
                if i >= 50:  
                    break
                print(line.decode('utf-8').strip()) 
if __name__ == "__main__":
    main()
```
> 4. Sau khi lÆ°u file `main.py`, thá»±c hiá»‡n lá»‡nh `docker-compose up run`
> 5. Káº¿t quáº£ sau khi thá»±c hiá»‡n
![Screenshot 2025-04-24 133824](https://github.com/user-attachments/assets/9b19ff56-eee5-41e7-a62b-5050c8958066)


## EXERCISE-4

> 1. Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-4`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-4 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/0429e78f-9d6b-4c9c-8d67-c06d6831a270)

> 3. Ná»™i dung file `main.py`
```
import os
import json
import csv
import glob

def flatten\_json(nested\_json, parent\_key='', sep='\_'):

Â  Â  """Giáº£i nÃ©n JSON lá»“ng nhau thÃ nh cáº¥u trÃºc pháº³ng (flat structure)"""

Â  Â  items = []

Â  Â  if isinstance(nested\_json, dict): Â # Kiá»ƒm tra náº¿u lÃ  dictionary

Â  Â  Â  Â  for k, v in nested\_json.items():

Â  Â  Â  Â  Â  Â  new\_key = f"{parent\_key}{sep}{k}" if parent\_key else k

Â  Â  Â  Â  Â  Â  if isinstance(v, dict): Â # Náº¿u giÃ¡ trá»‹ lÃ  dict, tiáº¿p tá»¥c giáº£i nÃ©n

Â  Â  Â  Â  Â  Â  Â  Â  items.extend(flatten\_json(v, new\_key, sep=sep).items())

Â  Â  Â  Â  Â  Â  elif isinstance(v, list): Â # Náº¿u giÃ¡ trá»‹ lÃ  list, giáº£i nÃ©n tá»«ng pháº§n tá»­

Â  Â  Â  Â  Â  Â  Â  Â  for i, sub\_item in enumerate(v):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  items.extend(flatten\_json(sub\_item, f"{new\_key}{sep}{i}", sep=sep).items())

Â  Â  Â  Â  Â  Â  else: Â # Náº¿u giÃ¡ trá»‹ khÃ´ng pháº£i dict hoáº·c list (vÃ­ dá»¥ nhÆ° sá»‘, chuá»—i, boolean)

Â  Â  Â  Â  Â  Â  Â  Â  items.append((new\_key, v))

Â  Â  elif isinstance(nested\_json, list): Â # Kiá»ƒm tra náº¿u lÃ  list

Â  Â  Â  Â  for i, sub\_item in enumerate(nested\_json):

Â  Â  Â  Â  Â  Â  items.extend(flatten\_json(sub\_item, f"{parent\_key}{sep}{i}", sep=sep).items())

Â  Â  else:

Â  Â  Â  Â  # Náº¿u giÃ¡ trá»‹ lÃ  kiá»ƒu khÃ¡c (vÃ­ dá»¥ float, int, string), tráº£ vá» giÃ¡ trá»‹ trá»±c tiáº¿p

Â  Â  Â  Â  items.append((parent\_key, nested\_json))

Â  Â  return dict(items)

def convert\_json\_to\_csv(json\_file, csv\_file):

Â  Â  """Chuyá»ƒn Ä‘á»•i tá»‡p JSON thÃ nh tá»‡p CSV"""

Â  Â  with open(json\_file, 'r') as f:

Â  Â  Â  Â  data = json.load(f)

Â  Â  # Giáº£i nÃ©n JSON lá»“ng nhau

Â  Â  flat\_data = flatten\_json(data)

Â  Â  # LÆ°u dá»¯ liá»‡u vÃ o CSV

Â  Â  with open(csv\_file, 'w', newline='', encoding='utf-8') as f:

Â  Â  Â  Â  writer = csv.DictWriter(f, fieldnames=flat\_data.keys())

Â  Â  Â  Â  writer.writeheader()

Â  Â  Â  Â  writer.writerow(flat\_data)

def process\_json\_files\_in\_directory(data\_directory):

Â  Â  """Duyá»‡t qua thÆ° má»¥c vÃ  chuyá»ƒn Ä‘á»•i táº¥t cáº£ tá»‡p JSON thÃ nh CSV"""

Â  Â  # TÃ¬m táº¥t cáº£ tá»‡p .json trong thÆ° má»¥c vÃ  cÃ¡c thÆ° má»¥c con

Â  Â  json\_files = glob.glob(os.path.join(data\_directory, '**', '*.json'), recursive=True)

Â  Â  for json\_file in json\_files:

Â  Â  Â  Â  csv\_file = json\_file.replace('.json', '.csv')

Â  Â  Â  Â  convert\_json\_to\_csv(json\_file, csv\_file)

Â  Â  Â  Â  print(f"ÄÃ£ chuyá»ƒn Ä‘á»•i {json\_file} thÃ nh {csv\_file}")

def main():

Â  Â  # ThÆ° má»¥c chá»©a dá»¯ liá»‡u

Â  Â  data\_directory = './data' Â # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n náº¿u cáº§n

Â  Â  process\_json\_files\_in\_directory(data\_directory)

if \_\_name\_\_ == "\_\_main\_\_":

Â  Â  main()
```

> 4. Sau khi save file ` main.py`, thá»±c thi lá»‡nh `docker-compose up run`
> 5. Káº¿t quáº£ sau khi thá»±c hiá»‡n:

![image](https://github.com/user-attachments/assets/52637e8a-7e04-48de-9cfc-7dc66e3c5ea5)

![image](https://github.com/user-attachments/assets/ca55d07c-a19c-4235-aa86-2c2815547f2b)

![image](https://github.com/user-attachments/assets/00fd665a-2b77-4ac1-9dc3-c069996521ad)

## EXERCISE-5

> 1.Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n thÆ° má»¥c táº¡i CMD thÃ nh `Exercise-5`

> 2. Cháº¡y lá»‡nh docker `build --tag=exercise-5 .` Ä‘á»ƒ build image Docker (QuÃ¡ trÃ¬nh diá»…n ra trong 2 â€“ 3 phÃºt)
> ![image](https://github.com/user-attachments/assets/3eb12b93-1146-4adf-bba8-5ad4cc3750fd)

#### Ná»™i dung file main.py:
```
import psycopg2
import csv

# Káº¿t ná»‘i Ä‘áº¿n PostgreSQL
conn = psycopg2.connect(

Â  Â  dbname="postgres", Â # TÃªn cÆ¡ sá»Ÿ dá»¯ liá»‡u

Â  Â  user="postgres", Â  Â # TÃªn ngÆ°á»i dÃ¹ng PostgreSQL

Â  Â  password="postgres",# Máº­t kháº©u PostgreSQL

Â  Â  host="postgres", Â  Â # MÃ¡y chá»§ (PostgreSQL cháº¡y trÃªn localhost)

Â  Â  port="5432" Â  Â  Â  Â  # Cá»•ng PostgreSQL (máº·c Ä‘á»‹nh)

)

# Táº¡o má»™t con trá» Ä‘á»ƒ thá»±c thi cÃ¡c cÃ¢u lá»‡nh SQL

with conn.cursor() as cur:

Â  Â  # 1. XÃ³a táº¥t cáº£ cÃ¡c rÃ ng buá»™c khÃ³a ngoáº¡i náº¿u cÃ³

Â  Â  remove\_constraints = """

Â  Â  ALTER TABLE IF EXISTS orders DROP CONSTRAINT IF EXISTS orders\_product\_id\_fkey;

Â  Â  """

Â  Â  cur.execute(remove\_constraints)

Â  Â  conn.commit()

Â  Â  # 2. XÃ³a cÃ¡c báº£ng náº¿u Ä‘Ã£ tá»“n táº¡i

Â  Â  drop\_tables = """

Â  Â  DROP TABLE IF EXISTS transactions, accounts, products CASCADE;

Â  Â  """

Â  Â  cur.execute(drop\_tables)

Â  Â  conn.commit()

Â  Â  # 3. Táº¡o láº¡i cÃ¡c báº£ng

Â  Â  create\_products\_table = """

Â  Â  CREATE TABLE IF NOT EXISTS products (

Â  Â  Â  Â  product\_id INT PRIMARY KEY,

Â  Â  Â  Â  product\_code VARCHAR(10),

Â  Â  Â  Â  product\_description VARCHAR(255)

Â  Â  );

Â  Â  """

Â  Â  

Â  Â  # Táº¡o báº£ng accounts

Â  Â  create\_accounts\_table = """

Â  Â  CREATE TABLE IF NOT EXISTS accounts (

Â  Â  Â  Â  customer\_id INT PRIMARY KEY,

Â  Â  Â  Â  first\_name VARCHAR(100),

Â  Â  Â  Â  last\_name VARCHAR(100),

Â  Â  Â  Â  address\_1 VARCHAR(255),

Â  Â  Â  Â  address\_2 VARCHAR(255),

Â  Â  Â  Â  city VARCHAR(100),

Â  Â  Â  Â  state VARCHAR(50),

Â  Â  Â  Â  zip\_code VARCHAR(20),

Â  Â  Â  Â  join\_date DATE

Â  Â  );

Â  Â  """

Â  Â  

Â  Â  # Táº¡o báº£ng transactions (sau khi báº£ng products Ä‘Ã£ Ä‘Æ°á»£c táº¡o)

Â  Â  create\_transactions\_table = """

Â  Â  CREATE TABLE IF NOT EXISTS transactions (

Â  Â  Â  Â  transaction\_id VARCHAR(50) PRIMARY KEY,

Â  Â  Â  Â  transaction\_date DATE,

Â  Â  Â  Â  product\_id INT,

Â  Â  Â  Â  product\_code VARCHAR(10),

Â  Â  Â  Â  product\_description VARCHAR(255),

Â  Â  Â  Â  quantity INT,

Â  Â  Â  Â  account\_id INT

Â  Â  );

Â  Â  """

Â  Â  

Â  Â  # 4. Cháº¡y cÃ¡c cÃ¢u lá»‡nh táº¡o báº£ng

Â  Â  print("Creating products table...")

Â  Â  cur.execute(create\_products\_table) Â # Äáº£m báº£o táº¡o báº£ng products trÆ°á»›c

Â  Â  print("Creating accounts table...")

Â  Â  cur.execute(create\_accounts\_table)

Â  Â  print("Creating transactions table...")

Â  Â  cur.execute(create\_transactions\_table)

Â  Â  # Commit changes

Â  Â  conn.commit()

Â  Â  # 5. ThÃªm khÃ³a ngoáº¡i sau khi cÃ¡c báº£ng Ä‘Ã£ Ä‘Æ°á»£c táº¡o

Â  Â  add\_foreign\_keys = """

Â  Â  ALTER TABLE transactions

Â  Â  ADD CONSTRAINT fk\_product\_id FOREIGN KEY (product\_id) REFERENCES products(product\_id) ON DELETE CASCADE,

Â  Â  ADD CONSTRAINT fk\_account\_id FOREIGN KEY (account\_id) REFERENCES accounts(customer\_id) ON DELETE CASCADE;

Â  Â  """

Â  Â  print("Adding foreign key constraints...")

Â  Â  cur.execute(add\_foreign\_keys)

Â  Â  

Â  Â  # Commit changes

Â  Â  conn.commit()

Â  Â  # 6. ChÃ¨n dá»¯ liá»‡u tá»« CSV vÃ o cÃ¡c báº£ng

Â  Â  def load\_data\_from\_csv(csv\_file, table\_name, columns):

Â  Â  Â  Â  with open(csv\_file, 'r') as file:

Â  Â  Â  Â  Â  Â  reader = csv.reader(file)

Â  Â  Â  Â  Â  Â  next(reader) Â # Bá» qua dÃ²ng tiÃªu Ä‘á» (header row)

Â  Â  Â  Â  Â  Â  

Â  Â  Â  Â  Â  Â  for row in reader:

Â  Â  Â  Â  Â  Â  Â  Â  # Táº¡o cÃ¢u truy váº¥n Ä‘á»ƒ chÃ¨n dá»¯ liá»‡u

Â  Â  Â  Â  Â  Â  Â  Â  query = f"INSERT INTO {table\_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})"

Â  Â  Â  Â  Â  Â  Â  Â  cur.execute(query, row)

Â  Â  Â  Â  

Â  Â  Â  Â  conn.commit()

Â  Â  # 7. ChÃ¨n dá»¯ liá»‡u cho tá»«ng báº£ng

Â  Â  load\_data\_from\_csv("data/accounts.csv", "accounts", ["customer\_id", "first\_name", "last\_name", "address\_1", "address\_2", "city", "state", "zip\_code", "join\_date"])

Â  Â  load\_data\_from\_csv("data/products.csv", "products", ["product\_id", "product\_code", "product\_description"])

Â  Â  load\_data\_from\_csv("data/transactions.csv", "transactions", ["transaction\_id", "transaction\_date", "product\_id", "product\_code", "product\_description", "quantity", "account\_id"])

# 8. ÄÃ³ng káº¿t ná»‘i

conn.close()

print("Data has been loaded successfully.")
```

> 3. Sau khi lÆ°u láº¡i, thá»±c thi lá»‡nh `docker-compose up run`
> 4. Káº¿t quáº£ sau khi thá»±c hiá»‡n:
![image](https://github.com/user-attachments/assets/e4013e15-1978-4dff-926d-69ac7c8b3a3e)
> Truy váº¥n cÃ¡c báº£ng vá»«a táº¡o trong DBeaver
![image](https://github.com/user-attachments/assets/5ead3335-5ae2-4cee-b049-52af90313eae)

## PIPELINE Tá»° Äá»˜NG THá»°C HIá»†N BÃ€I Táº¬P 1- 5
#### Code cho pipeline.py:
```
import os
import subprocess

# List cÃ¡c Exercise báº¡n muá»‘n cháº¡y
exercises = ['Exercise-1', 'Exercise-2', 'Exercise-3', 'Exercise-4', 'Exercise-5']

# HÃ m kiá»ƒm tra xem image Ä‘Ã£ cÃ³ chÆ°a
def check_image_exists(image_name):
    result = subprocess.run(['docker', 'images', '-q', image_name], stdout=subprocess.PIPE)
    return result.stdout.decode().strip() != ''

# HÃ m build image náº¿u chÆ°a cÃ³
def build_image(exercise_name):
    print(f"Image {exercise_name} chÆ°a cÃ³, báº¯t Ä‘áº§u build...")
    result = subprocess.run(['docker', 'build', '-t', exercise_name, f'D:/NMKTDL/data-engineering-practice-main/Exercises/{exercise_name}'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print(f"Build image {exercise_name} tháº¥t báº¡i. Dá»«ng pipeline.")
        print(result.stderr.decode())
        exit(1)
    print(f"Build image {exercise_name} thÃ nh cÃ´ng.")

# HÃ m cháº¡y docker-compose
def run_docker_compose(exercise_name):
    print(f"Äang cháº¡y {exercise_name} báº±ng image {exercise_name}...")
    compose_file = f'D:/NMKTDL/data-engineering-practice-main/Exercises/{exercise_name}/docker-compose.yml'
    result = subprocess.run(['docker-compose', '-f', compose_file, 'up'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print(f"Lá»—i khi cháº¡y {exercise_name}. Dá»«ng pipeline.")
        print(result.stderr.decode())
        exit(1)
    
    # Kiá»ƒm tra logs cá»§a cÃ¡c container
    print("Kiá»ƒm tra logs cá»§a cÃ¡c container...")
    logs_result = subprocess.run(['docker-compose', '-f', compose_file, 'logs'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    print(logs_result.stdout.decode())  # In logs Ä‘á»ƒ xem chi tiáº¿t

    print(f"{exercise_name} Ä‘Ã£ hoÃ n táº¥t!")

# Pipeline
def run_pipeline():
    for exercise in exercises:
        # Kiá»ƒm tra image Ä‘Ã£ tá»“n táº¡i chÆ°a
        if not check_image_exists(exercise.lower()):
            build_image(exercise)
        else:
            print(f"Image {exercise} Ä‘Ã£ cÃ³ sáºµn.")
        
        # Cháº¡y docker-compose cho bÃ i
        run_docker_compose(exercise)

    print("\nPipeline hoÃ n táº¥t!")

if __name__ == "__main__":
    run_pipeline()
```
> #### Káº¿t quáº£ thá»±c hiá»‡n:
> ##### Exercise-1
> ![image](https://github.com/user-attachments/assets/63d6cecb-88f2-48c4-816d-1dfc4b767f61)
> ##### Exercise-2 & 3
> ![image](https://github.com/user-attachments/assets/fedd1e65-6da1-4dc1-b9c3-ad1e2b8f21a3)
> ##### Exercise-4
> ![image](https://github.com/user-attachments/assets/71196633-75a3-4ead-b33b-21cdd6eafd2f)
> 

### Cáº¤U TRÃšC THÆ¯ Má»¤C Äá»‚ CHáº Y DAG AIRFLOW
```
data-engineering-practice-Le_Trung_Huu/
â”‚
â”œâ”€â”€ dags/                    â† ğŸ“‚ Chá»©a pipeline_dag.py
â”‚   â””â”€â”€ pipeline_dag.py  
â”‚
â”œâ”€â”€ Exercises/                   â† ğŸ“‚ Chá»©a cÃ¡c bÃ i táº­p vá»›i Dockerfile riÃªng
â”‚   â”œâ”€â”€ Exercise-1/
â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”œâ”€â”€ Exercise-2/
â”‚   â”‚   â”œâ”€â”€ main.py 
â”‚   â”œâ”€â”€ Exercise-3/
â”‚   â”œâ”€â”€ Exercise-4/
â”‚   â””â”€â”€ Exercise-5/
â”‚
â”œâ”€â”€ pipeline.py                  â† ğŸ“„ Code pipeline gá»‘c náº¿u muá»‘n gá»i ngoÃ i Airflow
â””â”€â”€ requirements.txt
â””â”€â”€ docker-compose.yml       â† âœ… Cháº¡y trong thÆ° má»¥c nÃ y
â””â”€â”€ Dockerfile
```
#### Dockerfile
```
FROM python:3.10-slim

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
RUN pip install --no-cache-dir -r requirements.txt

# Sao chÃ©p mÃ£ nguá»“n tá»« thÆ° má»¥c hiá»‡n táº¡i vÃ o trong container
COPY . /app

WORKDIR /app

# Lá»‡nh cháº¡y khi container Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng
CMD ["python", "main.py"]
```
#### Docker-compose:
```
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network

  airflow-init:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    entrypoint: bash -c "
      airflow db init && \
      airflow users create \
        --username airflow \
        --password airflow \
        --firstname Air \
        --lastname Flow \
        --role Admin \
        --email airflow@example.com
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'True'
    ports:
      - "8080:8080"
    command: ["airflow", "webserver"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.10
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: ["airflow", "scheduler"]
    volumes:
      - ./dags:/opt/airflow/dags
      - ./Exercises:/opt/airflow/Exercises  # Mount thÆ° má»¥c Exercises tá»« ngoÃ i vÃ o container
    networks:
      - app-network

  pgadmin:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - postgres
    networks:
      - app-network

volumes:
  postgres-db-volume:

networks:
  app-network:
    driver: bridge

#docker-compose up airflow-init
```

#### Pipeline-dag.py
```
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import os
import subprocess

default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
}

def run_main_py(path):
    print(f"ğŸ” Äang cháº¡y: {path}")
    result = subprocess.run(["python", path], capture_output=True, text=True)
    print("ğŸ“„ STDOUT:", result.stdout)
    print("â— STDERR:", result.stderr)
    result.check_returncode()

with DAG(
    dag_id='exercise_main_pipeline',
    default_args=default_args,
    description='Cháº¡y táº¥t cáº£ cÃ¡c main.py trong má»—i Exercise hÃ ng ngÃ y lÃºc 10h sÃ¡ng',
    schedule_interval='0 10 * * *',  # 10:00 UTC má»—i ngÃ y
    start_date=datetime(2025, 4, 25),
    catchup=False,
    tags=["exercise"],
) as dag:

    exercises_dir = "/opt/airflow/Exercises"

    if not os.path.exists(exercises_dir):
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: {exercises_dir}")

    previous_task = None

    for ex in sorted(os.listdir(exercises_dir)):
        ex_path = os.path.join(exercises_dir, ex, "main.py")
        if os.path.isfile(ex_path):
            task = PythonOperator(
                task_id=f'run_{ex.lower()}',
                python_callable=run_main_py,
                op_args=[ex_path],
            )
            if previous_task:
                previous_task >> task
            previous_task = task
```

### Káº¾T QUáº¢ SAU KHI CHáº Y DAG
>![image](https://github.com/user-attachments/assets/749ac8e5-5aea-428b-b2b4-df0cf866040c)

> ![image](https://github.com/user-attachments/assets/b889a380-7201-49db-af30-2384068a9653)
>![image](https://github.com/user-attachments/assets/5c9d74f3-9391-4b29-8a4a-6bc10718b474)
